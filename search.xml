<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>更换证书后kubelet无法启动</title>
      <link href="/2022/09/08/kubernetes/geng-huan-zheng-shu-hou-kubelet-wu-fa-qi-dong/"/>
      <url>/2022/09/08/kubernetes/geng-huan-zheng-shu-hou-kubelet-wu-fa-qi-dong/</url>
      
        <content type="html"><![CDATA[<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081648156.png" alt="现象"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081649830.png" alt="现象2"></p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>这种问题都是出现在第一台初始化的master节点，因为当集群安装时候集群没有起来则第一台机器使用的是kubelet的证书，而kubeadm更新证书时候没有更新kubelet证书导致。</p><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><pre class="line-numbers language-none"><code class="language-none">cp /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.confcp /etc/kubernetes/kubelet.conf ~/.kube/config<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> cert </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>意外导致pvc状态为Terminating的恢复流程</title>
      <link href="/2022/09/07/kubernetes/pvc/pvc-yi-wai-dao-zhi-pvc-zhuang-tai-wei-terminating-de-hui-fu-liu-cheng/"/>
      <url>/2022/09/07/kubernetes/pvc/pvc-yi-wai-dao-zhi-pvc-zhuang-tai-wei-terminating-de-hui-fu-liu-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="模拟pvc故障问题"><a href="#模拟pvc故障问题" class="headerlink" title="模拟pvc故障问题"></a>模拟<code>pvc</code>故障问题</h2><h4 id="查看正常状态下pv以及pvc"><a href="#查看正常状态下pv以及pvc" class="headerlink" title="查看正常状态下pv以及pvc"></a>查看正常状态下<code>pv</code>以及<code>pvc</code></h4><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081501275.png" alt="image-20210414150001610"></p>  <pre class="line-numbers language-none"><code class="language-none">kubectl get pvc  -n ns-xmrkcipnc   -l app.kubernetes.io/part-of=redis-failoverkubectl get pv|grep ns-xmrkcipnc|grep redis<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="模拟pvc故障意外"><a href="#模拟pvc故障意外" class="headerlink" title="模拟pvc故障意外"></a>模拟<code>pvc</code>故障意外</h4><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081501917.png" alt="image-20210414150059508"></p>  <pre class="line-numbers language-none"><code class="language-none">kubectl delete  pvc  -n ns-xmrkcipnc   -l app.kubernetes.io/part-of=redis-failoverkubectl get pvc  -n ns-xmrkcipnc   -l app.kubernetes.io/part-of=redis-failover<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="pvc故障恢复流程"><a href="#pvc故障恢复流程" class="headerlink" title="pvc故障恢复流程"></a><code>pvc</code>故障恢复流程</h2><blockquote><p>⚠️有条件下请备份再操作，注意步骤</p></blockquote><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><ul><li><p><strong>申请并等待可以操作的窗口期，否则操作期间会导致业务异常以及部分数据丢失</strong></p></li><li><p>注意事项</p><ul><li>下面实施操作命令会根据条件有所变化，务必理解对应逻辑再操作避免出现数据丢失问题</li></ul></li></ul><h4 id="实施操作"><a href="#实施操作" class="headerlink" title="实施操作"></a>实施操作</h4><h5 id="修改pv状态（批量修改）"><a href="#修改pv状态（批量修改）" class="headerlink" title="修改pv状态（批量修改）"></a><strong>修改<code>pv</code>状态（批量修改）</strong></h5>  <pre class="line-numbers language-none"><code class="language-none"># 修改pv状态（注意查询的实体比对）for pv in `kubectl get pvc  -n ns-xmrkcipnc   -l app.kubernetes.io/part-of=redis-failover|grep Terminating|awk '{print $3}'`;do kubectl patch pv $pv -p '{"spec":{"claimRef":{"uid":""}}}';done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081501435.png" alt="image-20210414152401402"></p><h5 id="修改pv状态（单个修改）"><a href="#修改pv状态（单个修改）" class="headerlink" title="修改pv状态（单个修改）"></a>修改<code>pv</code>状态（单个修改）</h5>  <pre class="line-numbers language-none"><code class="language-none">kubectl edit pv pvc-342ccb9b-bc9f-4169-ac68-eca4a4193550spec:  accessModes:  - ReadWriteOnce  capacity:    storage: 819Mi  claimRef:    apiVersion: v1    kind: PersistentVolumeClaim    name: data-redis-4x5yzix0a-2    namespace: ns-xmrkcipnc    resourceVersion: "16118531"    uid: ed581331-c029-4bd5-a62d-c41913b06bc8   # 删除改行<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081501611.png" alt="image-20210414160001072"></p><h5 id="查看pv状态"><a href="#查看pv状态" class="headerlink" title="查看pv状态"></a>查看<code>pv</code>状态</h5>  <pre class="line-numbers language-none"><code class="language-none"># 查看pv状态kubectl get pv `kubectl get pvc  -n ns-xmrkcipnc   -l app.kubernetes.io/part-of=redis-failover|grep Terminating|awk '{print $3}'`<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081501286.png" alt="image-20210414152220365"></p><h5 id="Pod停止"><a href="#Pod停止" class="headerlink" title="Pod停止"></a>Pod停止</h5><h5 id="略"><a href="#略" class="headerlink" title="略"></a>略</h5><h5 id="系统查看redis组件状态0-0为停止成功"><a href="#系统查看redis组件状态0-0为停止成功" class="headerlink" title="系统查看redis组件状态0/0为停止成功"></a>系统查看<code>redis</code>组件状态<code>0/0</code>为停止成功</h5><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081501925.png" alt="image-20210414152828647"></p>  <pre class="line-numbers language-none"><code class="language-none"># kubectl get sts -n ns-xmrkcipnc redis-4x5yzix0aNAME              READY   AGEredis-4x5yzix0a   0/0     46m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="pod启动"><a href="#pod启动" class="headerlink" title="pod启动"></a>pod启动</h5><p>略</p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081502302.png" alt="image-20210414152845823"></p><pre class="line-numbers language-none"><code class="language-none">### 查看组件恢复是否正常kubectl get sts -n ns-xmrkcipnc redis-4x5yzix0a<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>恢复结果检查</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081502715.png" alt="image-20210414152950472"></p><h3 id="检查恢复是否成功，pv以及pvc状态是否正常"><a href="#检查恢复是否成功，pv以及pvc状态是否正常" class="headerlink" title="检查恢复是否成功，pv以及pvc状态是否正常"></a>检查恢复是否成功，<code>pv</code>以及<code>pvc</code>状态是否正常</h3><h4 id="查看pod状态"><a href="#查看pod状态" class="headerlink" title="查看pod状态"></a>查看<code>pod</code>状态</h4>  <pre class="line-numbers language-none"><code class="language-none"># kubectl get pod  -n ns-xmrkcipnc   -l app.kubernetes.io/part-of=redis-failover<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081502231.png" alt="image-20210414153201020"></p><h4 id="查看pvc状态"><a href="#查看pvc状态" class="headerlink" title="查看pvc状态"></a>查看<code>pvc</code>状态</h4>  <pre class="line-numbers language-none"><code class="language-none"># kubectl get pvc  -n ns-xmrkcipnc   -l app.kubernetes.io/part-of=redis-failover<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081502803.png" alt="image-20210414153242987"></p><h4 id="查看pv状态-1"><a href="#查看pv状态-1" class="headerlink" title="查看pv状态"></a>查看<code>pv</code>状态</h4>  <pre class="line-numbers language-none"><code class="language-none">kubectl get pv|grep ns-xmrkcipnc|grep redis<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202209081502052.png" alt="image-20210414153325160"></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> pvc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>释放 Kubernetes 故障节点上的 RBD 卷</title>
      <link href="/2022/09/07/kubernetes/pvc/shi-fang-kubernetes-gu-zhang-jie-dian-shang-de-rbd-juan/"/>
      <url>/2022/09/07/kubernetes/pvc/shi-fang-kubernetes-gu-zhang-jie-dian-shang-de-rbd-juan/</url>
      
        <content type="html"><![CDATA[<h1 id="释放-Kubernetes-故障节点上的-RBD-卷"><a href="#释放-Kubernetes-故障节点上的-RBD-卷" class="headerlink" title="释放 Kubernetes 故障节点上的 RBD 卷"></a>释放 Kubernetes 故障节点上的 RBD 卷</h1><h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><ul><li>sts由于唯一性导致无法直接漂移，出现<code>Terminating</code>，以及长期<code>init</code>状态的<code>pod</code></li></ul><p><img src="./images/%E8%8A%82%E7%82%B9%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/image-20220902152404094.png" alt="image-20220902152404094"></p><ul><li>我们也无法直接删除该<code>pod</code>,强制删除后依然无法完成启动。</li></ul><p><img src="./images/%E8%8A%82%E7%82%B9%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/image-20220902152213882.png" alt="image-20220902152213882"></p><ul><li>原因</li></ul><p><code>kubectl describe pod</code>查看对应的失败原因情况下，由于存储后端为ceph-rbd，而ceph-rbd的pvc为支持RWO。</p><ul><li><code>Terminating</code>状态的pod的原因，无法完成unmap操作，也就是unattch操作，此时由于sts的唯一性，无法完成pod漂移操作，由于需要等待解绑操作的完成，则由于锁无法完成删除操作。</li><li>长期<code>init</code>状态，由于存储后端为ceph-rbd，而ceph-rbd的pvc为支持RWO，在不同节点上无法完成attach操作。</li></ul><p>如果是RWO则需要解决pvc无法挂载问题如下：</p><p><img src="./images/%E8%8A%82%E7%82%B9%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/image-20220902152032425.png" alt="image-20220902152032425"></p><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><h3 id="故障节点登陆："><a href="#故障节点登陆：" class="headerlink" title="故障节点登陆："></a>故障节点登陆：</h3><ul><li>停止并删除其中的容器 docker stop xxx</li><li>卸载该卷 umount</li><li>解除绑定操作 unmap /dev/rbdx</li></ul><h3 id="故障节点不可登陆："><a href="#故障节点不可登陆：" class="headerlink" title="故障节点不可登陆："></a>故障节点不可登陆：</h3><ul><li>找到对应的images信息  kubectl get pv PVNAME -o yaml|awk ‘/imageName|pool/‘</li></ul><p><img src="./images/%E8%8A%82%E7%82%B9%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/image-20220902153359488.png" alt="image-20220902153359488"></p><ul><li><p>查看该images信息状态  rbd status -p bigstorage csi-vol-24298ba1-2130-11ed-b43d-0e005bd3f3f6</p></li><li><p>将该关联拉黑. ceph osd blacklist add 172.199.1.0:0/286978028</p></li></ul><p><img src="./images/%E8%8A%82%E7%82%B9%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/image-20220902153459422.png" alt="image-20220902153459422"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.51cto.com/wendashuai/2493435">参考1</a></p><p><a href="https://blog.fleeto.us/post/unbound-rbd-from-a-notready-node/">参考2</a></p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> rook-ceph </tag>
            
            <tag> pvc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker-compose多个容器共用一个IP地址</title>
      <link href="/2022/05/20/docker-compose/docker-compose-chuang-jian-duo-ge-rong-qi-gong-yong-yi-ge-ip/"/>
      <url>/2022/05/20/docker-compose/docker-compose-chuang-jian-duo-ge-rong-qi-gong-yong-yi-ge-ip/</url>
      
        <content type="html"><![CDATA[<h1 id="如何使用docker-compose实现kubernetes-pod共用IP功能"><a href="#如何使用docker-compose实现kubernetes-pod共用IP功能" class="headerlink" title="如何使用docker-compose实现kubernetes pod共用IP功能"></a>如何使用docker-compose实现kubernetes pod共用IP功能</h1><h2 id="创建docker网络"><a href="#创建docker网络" class="headerlink" title="创建docker网络"></a>创建docker网络</h2><pre class="line-numbers language-none"><code class="language-none">docker network create -d macvlan --subnet=172.16.111.0/16 --gateway=172.16.0.254 -o parent=macvlan0 mac1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="配置docker-compose"><a href="#配置docker-compose" class="headerlink" title="配置docker-compose"></a>配置docker-compose</h2><pre class="line-numbers language-none"><code class="language-none">version: '2'services:  test1:    image: busybox    command: sh -c "sleep 36000000"    networks:      mac1:        ipv4_address: 172.16.111.152  test2:    image: busybox    command: sh -c "sleep 36000000"    network_mode: "service:test1"    depends_on:      - test1networks:  mac1:    external: true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><pre class="line-numbers language-none"><code class="language-none"># docker-compose exec test1 ifconfig eth0eth0      Link encap:Ethernet  HWaddr 02:42:AC:10:6F:98          inet addr:172.16.111.152  Bcast:172.16.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:307584 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0          RX bytes:20095408 (19.1 MiB)  TX bytes:0 (0.0 B)# docker-compose exec test2 ifconfig eth0eth0      Link encap:Ethernet  HWaddr 02:42:AC:10:6F:98          inet addr:172.16.111.152  Bcast:172.16.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:307881 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0          RX bytes:20115460 (19.1 MiB)  TX bytes:0 (0.0 B)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> docker-compose </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker-compose </tag>
            
            <tag> ip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>居于kubeadm部署的etcd备份恢复</title>
      <link href="/2022/05/20/etcd/etcd-gu-zhang-hui-fu/"/>
      <url>/2022/05/20/etcd/etcd-gu-zhang-hui-fu/</url>
      
        <content type="html"><![CDATA[<h1 id="当ETCD没有备份故障时候恢复"><a href="#当ETCD没有备份故障时候恢复" class="headerlink" title="当ETCD没有备份故障时候恢复"></a>当ETCD没有备份故障时候恢复</h1><p>在 <code>k8s</code>运行过程中， <code>etcd</code>集群异常的情况当时我们没有备份。我们该如何恢复ETCD呢。</p><table><thead><tr><th>端口</th><th>作用</th></tr></thead><tbody><tr><td>2379</td><td>提供 HTTP API 服务，供客户端交互</td></tr><tr><td>2380</td><td>和集群中其他节点通信</td></tr></tbody></table><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><pre class="line-numbers language-none"><code class="language-none"># 该工具可从容器中拷贝出来etcdctl # snapshot.db 文件来源，cp /var/lib/etcd/member/snap/db /root/backup/snapshot.db <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="ansible-执行"><a href="#ansible-执行" class="headerlink" title="ansible 执行"></a>ansible 执行</h2><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><pre class="line-numbers language-none"><code class="language-none">config.yamlall:  children:    # etcd 节点    etcd:      hosts:        IP1:          ansible_ssh_user: "root"          ansible_ssh_pass: "xxxxxx"          ansible_ssh_port: 22          hostname: "HOSTNAME1"  # ETCD名称          ip: "&lt;ETCD-IP1&gt;"        IP2:          ansible_ssh_user: "root"          ansible_ssh_pass: "xxxxxx"          ansible_ssh_port: 22          hostname: "HOSTNAME2"  # ETCD名称          ip: "&lt;ETCD-IP2&gt;"        IP3:          ansible_ssh_user: "root"          ansible_ssh_pass: "xxxxxx"          ansible_ssh_port: 22          hostname: "HOSTNAME3"  # ETCD名称          ip: "&lt;ETCD-IP3&gt;"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="playbook"><a href="#playbook" class="headerlink" title="playbook"></a>playbook</h2><pre class="line-numbers language-none"><code class="language-none"># 修改一下etcd-restore.yaml- hosts: etcd  remote_user: root  tasks:  - name: stop cluster    shell: mv /etc/kubernetes/manifests/{etcd.yaml,kube-apiserver.yaml} /tmp/  - name: remove data    shell:  rm -rf /var/lib/etcd/  - name: restone etcd      # 没有备份时候恢复方法    shell: sleep 2&amp;&amp; ETCDCTL_API=3 etcdctl snapshot restore /root/backup/snapshot.db --skip-hash-check --name {{hostname}} --initial-cluster HOSTNAME1=https://ETCD-IP1:2380,HOSTNAME2=https://ETCD-IP2:2380,HOSTNAME3=https://ETCD-IP3:2380  --initial-cluster-token etcd --initial-advertise-peer-urls https://{{ip}}:2380 --data-dir=/var/lib/etcd        # 有备份时候恢复方法    #shell: sleep 2&amp;&amp; ETCDCTL_API=3 etcdctl snapshot restore /root/backup/etcd-snapshot-20220517.db --name {{hostname}} --initial-cluster HOSTNAME1=https://ETCD-IP1:2380,HOSTNAME2=https://ETCD-IP2:2380,HOSTNAME3=https://ETCD-IP3:2380  --initial-cluster-token etcd --initial-advertise-peer-urls https://{{ip}}:2380 --data-dir=/var/lib/etcd  - name: start cluster    shell: mv /tmp/{etcd.yaml,kube-apiserver.yaml} /etc/kubernetes/manifests/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="执行恢复"><a href="#执行恢复" class="headerlink" title="执行恢复"></a>执行恢复</h2><pre class="line-numbers language-none"><code class="language-none">ansible -i config.yaml etcd-restore.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> etcd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> etcd </tag>
            
            <tag> kubeadm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes基础操作命令</title>
      <link href="/2022/02/11/bases/ji-chu-cao-zuo-ming-ling/"/>
      <url>/2022/02/11/bases/ji-chu-cao-zuo-ming-ling/</url>
      
        <content type="html"><![CDATA[<h2 id="操作命令"><a href="#操作命令" class="headerlink" title="操作命令"></a>操作命令</h2><h3 id="集群信息"><a href="#集群信息" class="headerlink" title="集群信息"></a>集群信息</h3><pre class="line-numbers language-none"><code class="language-none">kubectl cluster-info<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a><code>namespace</code></h3><ul><li>查看<code>&lt;namespace&gt;</code></li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl get ns<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h3><ul><li>查看节点</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl get nodes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>查看节点信息</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl get node -o wide <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>查看节点CPU和内存占用</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl top node <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>查看节点详细信息</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl describe node &lt;NODENAME&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="POD"><a href="#POD" class="headerlink" title="POD"></a><code>POD</code></h3><ul><li>查看指定<code>namespace</code>下的<code>pod</code></li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl get pod -n &lt;NAMESPACE&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>通过<code>label</code>查看pod</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl get pod -n rook-ceph -l app=rook-ceph-osd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h3><ul><li>直接查看日志</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl log -f -n &lt;NAMESPACE&gt; &lt;PODNAME&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>查看重启前日志</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl log -f -n &lt;NAMESPACE&gt; &lt;PODNAME&gt; -p <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>查看指定容器日志</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl log -f -n &lt;NAMESPACE&gt; &lt;PODNAME&gt; -c &lt;CONTAINER NAME&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="编辑"><a href="#编辑" class="headerlink" title="编辑"></a>编辑</h3><ul><li>直接编辑yaml</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl edit &lt;对像类型&gt; &lt;对像名称&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><ul><li>普通删除</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl delete &lt;对像类型&gt; &lt;对像名称&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>强制删除</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl delete &lt;对像类型&gt; &lt;对像名称&gt; --force --<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="SVC"><a href="#SVC" class="headerlink" title="SVC"></a>SVC</h3><ul><li>查看<code>svc</code></li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl get svc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>暴露对外访问</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl expose &lt;DEPLOYMENT/STATEFULSET&gt; &lt;NAME&gt; --name=&lt;SVCNAME&gt; --port=&lt;LOCAL PORT&gt; --target-port=&lt;REMOTE PORT&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="YAML"><a href="#YAML" class="headerlink" title="YAML"></a><code>YAML</code></h3><ul><li>根据<code>yaml</code>创建</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl create -f /path/yaml/file<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>根据<code>yaml</code>更新</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl apply -f /path/yaml/file<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>根据<code>yaml</code>删除</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl delete -f /path/yaml/file<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="下线节点"><a href="#下线节点" class="headerlink" title="下线节点"></a><strong>下线节点</strong></h3><pre class="line-numbers language-none"><code class="language-none">kubectl cordon &lt;node-name&gt;kubectl drain &lt;node-name&gt; --ignore-daemonsetskubectl delete node &lt;node-name&gt;对该节点进行 reset手动修改主机hosts移除对应机器解析记录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>虚拟机重启异常</title>
      <link href="/2022/02/11/kvm/xu-ni-ji-yi-chang/"/>
      <url>/2022/02/11/kvm/xu-ni-ji-yi-chang/</url>
      
        <content type="html"><![CDATA[<h1 id="虚拟机重启异常"><a href="#虚拟机重启异常" class="headerlink" title="虚拟机重启异常"></a>虚拟机重启异常</h1><h1 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h1><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202202111107079.png" alt="image-20220211110126180"></p><h1 id="修复方案"><a href="#修复方案" class="headerlink" title="修复方案"></a>修复方案</h1><ul><li>执行修复</li></ul><pre class="line-numbers language-none"><code class="language-none">xfs_repair /dev/dm-0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>出现异常</li></ul><pre class="line-numbers language-none"><code class="language-none">xfs_repair： cannot open /dev/dm-0: Device or resource busy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>正确解决方案</p></blockquote><ul><li>执行修复</li></ul><pre class="line-numbers language-none"><code class="language-none">umount /dev/mapper/centos-rootxfs_repair -v -L /dev/mapper/centos-rootreboot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gitlab+gitlab-runner搭建自动化部署</title>
      <link href="/2022/01/12/cicd/gitlab-gitlab-runner-da-jian-zi-dong-hua-bu-shu/"/>
      <url>/2022/01/12/cicd/gitlab-gitlab-runner-da-jian-zi-dong-hua-bu-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>实现自动部署</p><ul><li>开发人员上传代码到gitlab</li><li>gitlab-runner 检测到操作便开始自动部署</li><li>部署检测代码的是java还是web，检测需要部署的端口，实现根据代码和端口部署</li><li>部署完成发送信息到企业微信<h1 id="分析实现步骤"><a href="#分析实现步骤" class="headerlink" title="分析实现步骤"></a>分析实现步骤</h1></li><li>安装gitlab-runner</li><li>在需要部署java程序的机器上绑定 ，tags为test部署java程序</li><li>在需要部署web程序的机器上绑定 ，tags为test部署web程序</li><li>编写.gitlab-ci.yml放在项目的第一级目录</li><li>编写shell脚本实现部署</li><li>实现企业微信报警</li><li>检测是否自动部署<h1 id="安装gitlab"><a href="#安装gitlab" class="headerlink" title="安装gitlab"></a>安装gitlab</h1><a href="https://www.jianshu.com/p/8d981d1bff9a">Centos7搭建gitlab</a><h1 id="部署gitlab-runner"><a href="#部署gitlab-runner" class="headerlink" title="部署gitlab-runner"></a>部署gitlab-runner</h1><blockquote><p>使用gitlab-runner实现自动部署</p></blockquote><pre class="line-numbers language-none"><code class="language-none"># 安装repositorycurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash# 安装gitlab-runneryum install gitlab-runner<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>在需要部署的机器上注册</p></blockquote><h1 id="url以及token获取"><a href="#url以及token获取" class="headerlink" title="url以及token获取"></a>url以及token获取</h1><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206846.png" alt="url以及token位置"></li></ul><pre class="line-numbers language-none"><code class="language-none">[root@test2 SHELL]# gitlab-runner registerRuntime platform                                    arch=amd64 os=linux pid=53435 revision=d0b76032 version=12.0.2Running in system-mode.                                                                               Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):http://192.168.0.71/gitlab/   #输入URLPlease enter the gitlab-ci token for this runner:-rwbBw2y7GmL7smxuoxt  #输入TOKENPlease enter the gitlab-ci description for this runner:[test2.laozios.com]: test    #后面脚本需要用到Please enter the gitlab-ci tags for this runner (comma separated):test                                   #后面脚本需要用到Registering runner... succeeded                     runner=-rwbBw2yPlease enter the executor: parallels, kubernetes, virtualbox, docker+machine, docker-ssh+machine, docker, docker-ssh, shell, ssh:shell                                 #通过shellRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206944.png" alt="执行过程"></p><blockquote><p>查看结果</p></blockquote><ul><li>命令行查看<pre class="line-numbers language-none"><code class="language-none">gitlab-runner list <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206022.png" alt="查看是否绑定成功"></li><li>gitlab页面查看<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206830.png" alt="查看结果"><h1 id="重复上面步骤"><a href="#重复上面步骤" class="headerlink" title="重复上面步骤"></a>重复上面步骤</h1></li><li>刚刚绑定的是test应该为对于的【java】【web】<h1 id="编写-gitlab-ci-yml文件"><a href="#编写-gitlab-ci-yml文件" class="headerlink" title="编写.gitlab-ci.yml文件"></a>编写.gitlab-ci.yml文件</h1><pre class="line-numbers language-none"><code class="language-none">stages:  - deploy  - notice-success  - notice-failurepackage:Project:  stage: deploy  only:    - /^feature.*$/    - /^release.*$/  variables:    ############必须配置############    ## 连接API的接口以及NGINX端口地址    APIPORT: 9992    NGINXPORT: 803    #项目名称即git名称    projectName: $CI_PROJECT_NAME    #git idea 拉代码的git地址    gitUrl: $CI_REPOSITORY_URL    #工程所在目录    baseDir: '/home/gitlab-runner/${CI_PROJECT_NAME}'    ############选配############    #打包所在目录    buildDir: '/home/gitlab-runner/builds'    #打包环境    branch: $CI_COMMIT_REF_NAME  script:    - bash /SHELL/installPack $CI_PROJECT_NAME  $CI_REPOSITORY_URL  $CI_COMMIT_REF_NAME $APIPORT  $NGINXPORT  tags:    - webnotice_job:Project:  variables:    branch: $CI_COMMIT_REF_NAME    projectName: $CI_PROJECT_NAME  stage: notice-failure  only:    - /^feature.*$/    - /^release.*$/  script:    - if [[ ${branch:0:8} = "feature/" ]];then env="dev" ;elif [[ ${branch:0:8} = "release-" ]];then  env="test";fi    - python3 /SHELL/buildNotice.py $env $branch 失败  $projectName  when: on_failure  tags:    - webnotice_job:Project:  variables:    branch: $CI_COMMIT_REF_NAME    projectName: $CI_PROJECT_NAME  stage: notice-success  only:    - /^feature.*$/    - /^release.*$/  script:    - if [[ ${branch:0:8} = "feature/" ]];then env="dev" ;elif [[ ${branch:0:8} = "release-" ]];then  env="test";fi    - python3 /SHELL/buildNotice.py $env $branch  成功  $projectName  when: on_success  tags:    - web<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>实现环境判断并实现部署脚本</p></blockquote><pre class="line-numbers language-none"><code class="language-none">#!/bin/bash## 拉取代码进行安装########获取编译函数###########source /SHELL/buildPack ############必须配置#############项目名称即git名称projectName=$1#git idea 拉代码的git地址gitUrl=$2#打包分支branch=$3APIPORT=$4NGINXPORT=$5###########初始化参数##########################################if [ -z $APIPORT ];then   APIPORT="9991"fiif [ -z $NGINXPORT ];then   NGINXPORT="802"fi###根据分支判断环境if [[ ${branch:0:8} = "feature/" ]];then    env="dev"    APIPORT=$APIPORT    NGINXPORT=$NGINXPORTelif [[ ${branch:0:8} = "release/" ]];then    env="test"    APIPORT="9999"    NGINXPORT="801"fi###编译目录buildDir="/home/gitlab-runner/$env/$projectName/$branch"###进行部署######判断项目编译目录是否存在if [ ! -d ${buildDir} ];then    mkdir ${buildDir} -pficd ${buildDir}###该分支目录名字已经存在则删除该目录重新拉起if [ -e $projectName ];then    rm -rf ${buildDir}/${projectName}fi## 拉取分支到本地git  clone $gitUrl## 判断是否拉取成功，不成功退出if [ '0' != $? ]; then     echo "注意：更新发生错误！"     exit 1fi## 进入项目并且切换分支cd $projectName &amp;&amp; git checkout $branchif [ '0' != $? ]; then     echo "注意：切换分支发生错误！"    exit 3fi## 进行编译if [ $projectName = "web" ];then  ## 修改配置文件  echo $NGINXPORT  sed -i "s/\(^axios.defaults.baseURL = \).*/\1 \'http:\/\/192.168.0.xxx:$NGINXPORT\/api\\'/" src/main.js  ## 进行web编译  buildweb    ## 编译成功进行文件移动  if [ -d /ENV/$env/web/$NGINXPORT ];then    ## 文件存在：判断移动目录    if [ ! -d /ENV/$env/BACKUP/web/$NGINXPORT ];then        mkdir /ENV/$env/BACKUP/web/$NGINXPORT -p     fi    ## 文件存在：移动到上面目录    mv /ENV/$env/web/$NGINXPORT /ENV/$env/BACKUP/web/$NGINXPORT/web_`date "+%Y_%m_%d_%H_%M_%S"` &amp;&amp; \    mv ${buildDir}/$projectName/dist /ENV/$env/web/$NGINXPORT  else    echo "修改了端口先通知运维"    exit 6  fi  sed -i "s/\(proxy_pass.*:\).*/\1$APIPORT;/" /etc/nginx/conf.d/$NGINXPORT.conf   nginx -t &amp;&amp; nginx -s reload  elif [ $projectName = "java" ];then  ## 进行java编译  buildjava  ## 编译成功进行文件移动  if [ ! -d ${buildDir}/${projectName}/$branch/"$projectName"_build ];then     mkdir ${buildDir}/$projectName"_build" -p  fi  cd ${buildDir}/$projectName"_build"  unzip -oq ${buildDir}/$projectName/lw-admin/target/lw-admin.war -d ./  sed -i "s/\(active:\).*/\1 $env/" WEB-INF/classes/application.yml    ## 备份以前的文件  if [ -d /ENV/$env/tomcat/$APIPORT/ROOT ];then    ## 文件存在：判断移动目录    if [ ! -d /ENV/$env/BACKUP/tomcat/$APIPORT ];then        mkdir /ENV/$env/BACKUP/tomcat/$APIPORT -p     fi    ## 文件存在：移动到上面目录    mv /ENV/$env/tomcat/$APIPORT/ROOT /ENV/$env/BACKUP/tomcat/$APIPORT/ROOT_`date "+%Y_%m_%d_%H_%M_%S"` &amp;&amp; \    echo "`ls ${buildDir}/"$projectName"_build`"    echo "`pwd`"    mv ${buildDir}/"$projectName"_build /ENV/$env/tomcat/$APIPORT/ROOT    docker restart "$APIPORT"_tomcat  else    echo "修改了端口先通知运维"    exit 6  fielse  ## 没有在这次自动化规划之内  echo "该项目$projectName没有该这样自动化部署之内"  exit 3fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>实现编译</p></blockquote><pre class="line-numbers language-none"><code class="language-none">[root@test2 SHELL]# vim buildPack ##编译webbuildweb(){    cnpm  install &amp;&amp; \    cnpm rebuild node-sass &amp;&amp; cnpm run build    if [ $? = 0 ];then       echo "编译成功"    else       echo "编译失败"       exit 4    fi}##编译javabuildjava(){    mvn clean &amp;&amp; \    mvn install &amp;&amp; \    mvn package    if [ $? = 0 ];then       echo "编译成功"    else       echo "编译失败"       exit 4    fi}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>获取企业微信信息</p></blockquote></li><li>创建应用<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206064.png" alt="创建应用"></li><li>查看绑定信息<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206434.png" alt="绑定信息"></li></ul><blockquote><p>实现企业微信通知</p></blockquote><pre class="line-numbers language-none"><code class="language-none">[root@test2 SHELL]# cat  buildNotice.py #!/usr/bin/python# -*- coding: utf-8 -*-import jsonimport requestsimport sysimport time##参数corpid = "wwXXXXX"secret = "LXXXXXXa64Bc"agentid = "100XXX2"#corpid = "wwXXXX2c"#secret = "_fhXXXXXXXXp-VpWvJc9U78"#agentid = "100XXXX3"localtime = time.asctime(time.localtime(time.time()))class WeChat(object):    def __init__(self, corpid, secret, agentid):        self.url = "https://qyapi.weixin.qq.com"        self.corpid = corpid        self.secret = secret        self.agentid = agentid    # 获取企业微信的 access_token    def access_token(self):        url_arg = '/cgi-bin/gettoken?corpid={id}&amp;corpsecret={crt}'.format(            id=self.corpid, crt=self.secret)        url = self.url + url_arg        response = requests.get(url=url)        text = response.text        self.token = json.loads(text)['access_token']    # 构建消息格式    def messages(self, msg):        values = {            "touser": '@all',            "msgtype": 'text',            "agentid": self.agentid,            "text": {'content': msg},            "safe": 0        }        # python 3        self.msg = (bytes(json.dumps(values), 'utf-8'))        # python 2        #self.msg = json.dumps(values)    # 发送信息    def send_message(self, msg):        self.access_token()        self.messages(msg)        send_url = '{url}/cgi-bin/message/send?access_token={token}'.format(            url=self.url, token=self.token)        response = requests.post(url=send_url, data=self.msg)        errcode = json.loads(response.text)['errcode']        if errcode == 0:            print('Succesfully')        else:            print('Failed')# 开发环境|测试环境 WEB|TEST 部署成功|部署失败#  python3 /SHELL/buildNotice.py dev web  成功def send():    print(sys.argv)    msg = "@所有小伙伴们：\r\n{_time}\r\n环境：{_env} \r\n分支：{_pro} \r\n状态：{_status}\r\nREPO:{_repo}\r\n有问题请@运维小伙伴。谢谢".format(_time=localtime,_env=sys.argv[1],_pro=sys.argv[2],_status=sys.argv[3],_repo=sys.argv[4])    #msg="jamestest"    wechat = WeChat(corpid, secret, agentid)    wechat.send_message(msg)send()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="推送代码实现部署"><a href="#推送代码实现部署" class="headerlink" title="推送代码实现部署"></a>推送代码实现部署</h1><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206236.png" alt="查看流程线"><br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121206677.png" alt="查看执行步骤"><br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121207461.png" alt="查看部署流程"><br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121207819.png" alt="查看通知"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121207908.png" alt="企业微信通知"></p><h1 id="进阶优化问题"><a href="#进阶优化问题" class="headerlink" title="进阶优化问题"></a>进阶优化问题</h1><ul><li>安装时候<pre class="line-numbers language-none"><code class="language-none">/usr/bin/gitlab-ci-multi-runner run --working-directory /home/gitlab-runner --config /etc/gitlab-runner/config.toml --service gitlab-runner --syslog --user gitlab-runner<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>如何修改gitlab-runner的工作路径<pre class="line-numbers language-none"><code class="language-none">--working-directory /home/gitlab-runner<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>修改用户执行用户<pre class="line-numbers language-none"><code class="language-none">--user gitlab-runner<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>配置文件<pre class="line-numbers language-none"><code class="language-none">--config /etc/gitlab-runner/config.toml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="如何查询"><a href="#如何查询" class="headerlink" title="如何查询"></a>如何查询</h1><pre class="line-numbers language-none"><code class="language-none">ps aux|grep gitlab-runnerroot      9217  2.9  0.0  44996 12988 ?        Ssl  Jul31 161:47 /usr/local/bin/gitlab-runner run --working-directory /home/gitlab-runner --config /etc/gitlab-runner/config.toml --service gitlab-runner --syslog --user gitlab-runnerroot     21162  0.0  0.0 112712   984 pts/4    S+   18:52   0:00 grep --color=auto gitlab-runner<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="通过启动文件修改"><a href="#通过启动文件修改" class="headerlink" title="通过启动文件修改"></a>通过启动文件修改</h2><pre class="line-numbers language-none"><code class="language-none">vim /etc/systemd/system/gitlab-runner.service[Unit]Description=GitLab RunnerAfter=syslog.target network.targetConditionFileIsExecutable=/usr/lib/gitlab-runner/gitlab-runner[Service]StartLimitInterval=5StartLimitBurst=10ExecStart=/usr/lib/gitlab-runner/gitlab-runner "run" "--working-directory" "/BUILD" "--config" "/etc/gitlab-runner/config.toml" "--service" "gitlab-runner" "--syslog" "--user" "root"Restart=alwaysRestartSec=120[Install]WantedBy=multi-user.target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h1><pre class="line-numbers language-none"><code class="language-none">systemctl daemon-reloadsystemctl start gitlab-runner<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><a href="http://fidding.me/article/111">参考</a></li></ul><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://docs.gitlab.com/runner/install/linux-repository.html">参考文档</a><br><a href="https://docs.gitlab.com/ce/ci/variables/predefined_variables.html">变量</a></p>]]></content>
      
      
      <categories>
          
          <category> cicd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> cicd </tag>
            
            <tag> gitlab </tag>
            
            <tag> gitlab-runner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flannel</title>
      <link href="/2022/01/12/cni/flannel/"/>
      <url>/2022/01/12/cni/flannel/</url>
      
        <content type="html"><![CDATA[<p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/cni/flannel/image-20220112162558328.png" alt="image-20220112162558328"></p><h2 id="网络基础"><a href="#网络基础" class="headerlink" title="网络基础"></a>网络基础</h2><h3 id="IP信息"><a href="#IP信息" class="headerlink" title="IP信息"></a>IP信息</h3><p>IP （Internet Protocol Address）是一种在Internet上的给主机编址的方式，也称为网际协议地址。IP地址是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址。</p><h3 id="交换机和网桥"><a href="#交换机和网桥" class="headerlink" title="交换机和网桥"></a>交换机和网桥</h3><p>交换机：交换机主要工作在 OSI 参考模型的第二层，也就是<strong>数据链路层</strong>。能够同时连接许多对端口，使得每一对相互通信的主机都能够像独占通信媒体那样，进行无冲突地传输数据。和集线器不同的是，集线器采取的是广播的方式，而交换机的数据传输是根据 MAC 地址表进行的，只有当 MAC 地址表中找不到地址的时候才进行广播处理。</p><p>网桥：网桥工作在 OSI 参考模型的第二层，也就是<strong>数据链路层</strong>。将相似的网络连接起来，并对网络的数据流通进行管理。网桥只有 2 个输入或者输出的端口，而交换机则有多个。而网桥里的 MAC 地址表则是一个端口对应多个地址，而在交换机里则是一个端口对应一个 MAC 地址。</p><h3 id="路由器"><a href="#路由器" class="headerlink" title="路由器"></a>路由器</h3><p>路由器工作在 OSI 参考模型的第三层，也就是<strong>网络层</strong>。主要对不同的网络中的数据进行存储、分组转发处理，使得数据从一个子网传输到另外一个子网里去，把数据包按照选定的路由算法传送到指定的位置。</p><h3 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h3><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251229989.svg" alt="img"></p><blockquote><p> 5 个内置的链(chain)</p></blockquote><ul><li>PREROUTING：接收的数据包刚进来，还没有经过路由选择，即还不知道数据包是要发给本机还是其它机器。这时会触发该 chain 上的规则。</li><li>INPUT：已经经过路由选择，并且该数据包的目的 IP 是本机，进入本地数据包处理流程。此时会触发该 chain 上的规则。</li><li>FORWARD：已经经过路由选择，但该数据包的目的 IP 不是本机，而是其它机器，进入 forward 流程。此时会触发该 chain 上的规则。</li><li>OUTPUT：本地程序要发出去的数据包刚到 IP 层，还没进行路由选择。此时会触发该 chain 上的规则。</li><li>POSTROUTING：本地程序发出去的数据包，或者转发(forward)的数据包已经经过了路由选择，即将交由下层发送出去。此时会触发该 chain 上的规则。</li></ul><blockquote><p>表</p></blockquote><ul><li>filter：一般的过滤功能</li><li>nat:用于nat功能（端口映射，地址映射等）</li><li>mangle:用于对特定数据包的修改</li><li>raw:有限级最高，设置raw时一般是为了不再让iptables做数据包的链接跟踪处理，提高性能</li></ul><p>表的处理优先级：raw&gt;mangle&gt;nat&gt;filter</p><blockquote><p>Targets 就是找到匹配的数据包之后怎么办，常见的有下面几种：</p></blockquote><ul><li>DROP：直接将数据包丢弃，不再进行后续的处理</li><li>RETURN： 跳出当前 chain，该 chain 里后续的 rule 不再执行</li><li>QUEUE： 将数据包放入用户空间的队列，供用户空间的程序处理</li><li>ACCEPT： 同意数据包通过，继续执行后续的 rule</li><li>其他： 跳转到其它用户自定义的 chain 继续执行</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251229997.png" alt="iptables"></p><h3 id="veth-pair-and-netns"><a href="#veth-pair-and-netns" class="headerlink" title="veth pair and netns"></a>veth pair and netns</h3><p>veth-pair 就是一对的虚拟设备接口，它都是成对出现的。一端连着协议栈，一端彼此相连着，犹如一根网线。</p><p>Network Namespace （以下简称netns）是Linux内核提供的一项实现网络隔离的功能，它能隔离多个不同的网络空间，并且各自拥有独立的网络协议栈，这其中便包括了网络接口（网卡），路由表，iptables规则等。docker的网络隔离用的就是netns。</p><h4 id="模拟一下docker实现通讯（视频演示过程中无法对外通讯由于网卡地址不是eth0而是macvlan0导致）"><a href="#模拟一下docker实现通讯（视频演示过程中无法对外通讯由于网卡地址不是eth0而是macvlan0导致）" class="headerlink" title="模拟一下docker实现通讯（视频演示过程中无法对外通讯由于网卡地址不是eth0而是macvlan0导致）"></a>模拟一下docker实现通讯（视频演示过程中无法对外通讯由于网卡地址不是eth0而是macvlan0导致）</h4><pre class="line-numbers language-none"><code class="language-none"># 新建network namespace，类似新建一台没有网络的机器[root@test-rook-server2 ~]# ip netns add demo# 新建veth pair，类似新建一根网线[root@test-rook-server2 ~]# ip link add veth-1 type veth peer name veth-2# 将veth pair放到demo netns中并配置IP启动，类似将网线一端插上并启动[root@test-rook-server2 ~]# ip link set dev veth-2 netns demo[root@test-rook-server2 ~]# ip link set dev veth-1 up[root@test-rook-server2 ~]# ip netns exec demo ip link set dev veth-2 up[root@test-rook-server2 ~]# ip netns exec demo ip addr add 10.0.0.2/24 dev veth-2# 创建网桥并启动，类似创建一台交换机，类似docker0# 网桥和交换机不同的是，网桥可配置IP，交换机没有IP[root@test-rook-server2 ~]# ip link add demo-docker0 type bridge[root@test-rook-server2 ~]# ip link set dev demo-docker0 up[root@test-rook-server2 ~]# ip addr add 10.0.0.1/24 dev demo-docker0# 将veth pair和网桥建立联系，类似将网线一端插入到交换机中# 原本由veth-2出来的数据会给veth-1处理，但是由于将veth-1和网桥建立了联系，veth-1降级，会将数据包给到demo-docker0进行处理[root@test-rook-server2 ~]# ip link set dev veth-1 master demo-docker0# 设置路由[root@test-rook-server2 ~]# ip netns exec demo ip route add default via 10.0.0.1 dev veth-2# 本地机器启动路由转发功能，并设置nat，类似办公室网络[root@test-rook-server2 ~]# sysctl -w net.ipv4.ip_forward=1net.ipv4.ip_forward = 1[root@test-rook-server2 ~]# iptables -A FORWARD --out-interface eth0 --in-interface demo-docker0 -j ACCEPT[root@test-rook-server2 ~]# iptables -A FORWARD --in-interface eth0 --out-interface demo-docker0 -j ACCEPT[root@test-rook-server2 ~]# iptables -t nat -A POSTROUTING --source 10.0.0.0/24 --out-interface eth0 -j MASQUERADE# 测试[root@test-rook-server2 ~]# ip netns exec demo ping 114.114.114.114 -c 3PING 114.114.114.114 (114.114.114.114) 56(84) bytes of data.64 bytes from 114.114.114.114: icmp_seq=1 ttl=250 time=5.13 ms64 bytes from 114.114.114.114: icmp_seq=2 ttl=250 time=4.81 ms64 bytes from 114.114.114.114: icmp_seq=3 ttl=250 time=3.61 ms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>解决arp内核限制</li></ul><pre class="line-numbers language-none"><code class="language-none">echo 1 &gt; /proc/sys/net/ipv4/conf/&lt;网卡名称&gt;/accept_localecho 0 &gt; /proc/sys/net/ipv4/conf/all/rp_filterecho 0 &gt; /proc/sys/net/ipv4/conf/&lt;网卡名称&gt;/rp_filter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="管理网络"><a href="#管理网络" class="headerlink" title="管理网络"></a>管理网络</h2><blockquote><p>flannel</p></blockquote><p>Flannel是为Kubernetes设计的一种简单易用的容器网络解决方案，将所有的Pod都组织在同一个子网的虚拟大二层网络中,Flannel支持的后端转发方式有UDP，vxlan，host-gw。我们这里讲vxlan作为后端转发模式。</p><ul><li>点对点vxlan</li></ul><pre class="line-numbers language-none"><code class="language-none">#                                                  对端Underlay地址  本地Underlay地址   物理网络接口ip link add vxlan0 type vxlan id 1 dstport 4789 remote 172.16.111.132 local 172.16.111.131 dev eth0ip addr add 172.20.1.2/24 dev vxlan0ip link set vxlan0 upip link add vxlan0 type vxlan id 1 dstport 4789 remote 172.16.111.131 local 172.16.111.132 dev eth0ip addr add 172.20.1.3/24 dev vxlan0ip link set vxlan0 up<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231892.png" alt="image-20220224143838939"></p><ul><li>多播模式vxlan</li></ul><pre class="line-numbers language-none"><code class="language-none"># 多播模式ip link add vxlan0 type vxlan id 1  local 172.16.111.131  group 239.1.1.1 dev eth0 dstport 4789<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>每个主机都可能有几十甚至上百个虚拟机/容器，需要加入到同一个VLAN中，而每个VLAN在一台主机上仅仅有一个VTEP这个如何建立每个的链接呢。</li></ul><p>可以用VETH Pair将容器连接到网桥，然后将VTEP也连接到网桥。VTEP通过物理网络相互联系。</p><ul><li><strong>分布式控制中心</strong></li></ul><p>由于使用点对点比较复杂，而且某些网络设备不支持多播，而且多播导致的不必要流量，通过在每个VTEP节点部署Agent，Agent联系控制中心，通过Agent获取通信所需要的信息（FDB+ARP）。</p><ul><li>这个模型是什么就是我们的flannel</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231564.png" alt="Flannel - 图1"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231884.png" alt="img{512x368}"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231781.jpg" alt="Flannel"></p><h3 id="如何通讯"><a href="#如何通讯" class="headerlink" title="如何通讯"></a>如何通讯</h3><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231723.jpg" alt="法兰绒网络流"></p><blockquote><p>当 flannel 使用 VXLAN backend 时，会创建一个名为 flannel.<vni> 的 VXLAN 设备，<vni> 代表 VXLAN Network Identifier，在 flannel 中 VNI 默认设置为 1，即默认设备名称为flannel.1 使用 <code>ip -d link show flannel.1</code>将显示有关此 VXALN 设备的详细信息</vni></vni></p></blockquote><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231633.png" alt="image-20220222143024397"></p><ul><li>输出所示，vxlan id 为 1，eth0 设备用于隧道，VXLAN UDP 端口为 8472，nolearning 标记禁用源地址学习意味着不使用组播，而是使用带有静态 L3 条目的单播</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231504.png" alt="image-20220222143239163"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231359.png" alt="image-20220222144605420"></p><blockquote><p> VXLAN 设备 flannel.1 与物理网络设备 eth0 链接，通过物理网络发送 VXLAN 流量。代理<code>flanneld</code>将填充节点 ARP 表以及网桥转发数据库，因此 flannel.1 知道如何转发物理网络内的流量。当找到新的 kubernetes 节点时（无论是在启动期间还是在创建时），<code>flanneld</code>添加</p></blockquote><ul><li>远程节点的 VXLAN 设备的 ARP 条目。(VXLAN设备IP-&gt;VXLAN设备MAC)</li><li>远程主机的 VXLAN fdb 条目。（VXLAN 设备 MAC-&gt;远程节点 IP）</li></ul><p>注：ARP是三层转发，FDB是用于二层转发</p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231760.png" alt="image-20220222150736174"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251231081.png" alt="image-20220222152513891"></p><h3 id="手动配置IP地址流程"><a href="#手动配置IP地址流程" class="headerlink" title="手动配置IP地址流程"></a>手动配置IP地址流程</h3><h4 id="网络插件流程模拟"><a href="#网络插件流程模拟" class="headerlink" title="网络插件流程模拟"></a>网络插件流程模拟</h4><pre class="line-numbers language-none"><code class="language-none">mkdir /test-cnicd /test-cnicat &gt; /test-cni/demo.conf &lt;&lt;"EOF"{    "cniVersion": "0.3.1",    "name": "demo",    "type": "bridge",    "bridge": "demo-br0",    "isGateway": true,    "ipMasq": true,    "ipam": {        "type": "host-local",        "subnet": "10.100.10.0/24",        "routes": [            { "dst": "0.0.0.0/0" }        ],        "rangeStart": "10.100.10.8",        "rangeEnd": "10.100.10.100",        "gateway": "10.100.10.1"    }}EOFcd /opt/cni/binip netns add demoip netns listCNI_COMMAND=ADD CNI_CONTAINERID=demo CNI_NETNS=/var/run/netns/demo CNI_IFNAME=eth0 CNI_PATH=/opt/cni/bin ./bridge &lt;/test-cni/demo.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232257.png" alt="image-20220221183140585"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232486.png" alt="image-20220224160105250"></p><h4 id="查看模拟结果"><a href="#查看模拟结果" class="headerlink" title="查看模拟结果"></a>查看模拟结果</h4><pre class="line-numbers language-none"><code class="language-none">ip aip netns exec demo ip a showiptables-save |grep demobrctl show<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232578.png" alt="image-20220221183505929"></p><pre class="line-numbers language-none"><code class="language-none">ip netns exec demo ip route ls /var/lib/cni/networks/demoip netns exec demo ip link set dev lo upip netns exec demo ping 10.100.10.1 -c 3ping 10.100.10.8 -c 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232281.png" alt="image-20220221183639550"></p><pre class="line-numbers language-none"><code class="language-none">ip netns exec demo ethtool -S eth0 ip link show | grep '^11:'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232529.png" alt="image-20220221184142075"></p><h3 id="模拟flannel-二进制配置测试？"><a href="#模拟flannel-二进制配置测试？" class="headerlink" title="模拟flannel 二进制配置测试？"></a>模拟flannel 二进制配置测试？</h3><pre class="line-numbers language-none"><code class="language-none">ip netns add flannel-demoip netns listCNI_COMMAND=ADD CNI_CONTAINERID=flannel-demo CNI_NETNS=/var/run/netns/flannel-demo CNI_IFNAME=eth0 CNI_PATH=/opt/cni/bin ./flannel &lt;/etc/cni/net.d/10-flannel.conflist<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232952.png" alt="image-20220221184643631"></p><pre class="line-numbers language-none"><code class="language-none">ip aip netns exec demo ip a showiptables-save |grep demobrctl show<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232877.png" alt="image-20220221184727197"></p><pre class="line-numbers language-none"><code class="language-none">ip netns exec flannel-demo ip route ls /var/lib/cni/networks/cbr0ip netns exec flannel-demo ip link set dev lo upip netns exec flannel-demo ping 172.199.0.1 -c 3ping 172.199.0.2 -c 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232558.png" alt="image-20220221185340117"></p><h4 id="flannel二进制和bridge区别"><a href="#flannel二进制和bridge区别" class="headerlink" title="flannel二进制和bridge区别"></a>flannel二进制和bridge区别</h4><blockquote><p>手动执行flannel和bridge区别过程有什么区别呢</p><p>手动执行flannel和kubelet调用flannel有什么区别呢</p></blockquote><pre class="line-numbers language-none"><code class="language-none"># 使用bridge的配置和flannel的配置差别ip netns exec demo ip route showip netns exec flannel-demo ip route show# 网段没写，怎么自动配置了呢读取了/run/flannel/subnet.env# 没写网关，自动创建flannel写入cat /etc/cni/net.d/10-flannel.conflist<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232054.png" alt="image-20220221185752108"></p><h3 id="flannel二进制网络和我们手动创建pod时候区别。"><a href="#flannel二进制网络和我们手动创建pod时候区别。" class="headerlink" title="flannel二进制网络和我们手动创建pod时候区别。"></a>flannel二进制网络和我们手动创建pod时候区别。</h3><ul><li>自动化写入网关</li><li>CNI_NETNS在哪里/var/lib/docker/netns</li><li>/run/flannel/subnet.env</li></ul><h4 id="什么了解flannel作用"><a href="#什么了解flannel作用" class="headerlink" title="什么了解flannel作用"></a>什么了解flannel作用</h4><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232275.png" alt="Flannel - 图2"></p><h4 id="了解创建组件的大致流程"><a href="#了解创建组件的大致流程" class="headerlink" title="了解创建组件的大致流程"></a>了解创建组件的大致流程</h4><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232205.png" alt="kubelet-cri-cni-flowchart"></p><h4 id="创建IP的细节"><a href="#创建IP的细节" class="headerlink" title="创建IP的细节"></a>创建IP的细节</h4><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251232378.png" alt="kubelet-cri-cni-interactions"></p><h3 id="flannel还有什么问题吗？"><a href="#flannel还有什么问题吗？" class="headerlink" title="flannel还有什么问题吗？"></a>flannel还有什么问题吗？</h3><ul><li>MTU为什么不是1500？</li></ul><blockquote><p>MTU为最大传输单元为1500，那我们为什么要设置1450呢，由于我们使用vxlan封包，新增了头数据，这样数据切片不会大于1450，新增vxlan头信息则不会大于1500，则在传输过程中就不会丢弃该包。</p></blockquote><ul><li>system 242导致的问题</li></ul><p>当使用 systemd 242+ 运行 flannel 时，在 flannel 对 flannel.1 接口的 mac 地址进行编程和 systemd 在虚拟接口上对 mac 地址进行编程之间似乎存在竞争条件。由于不正确的目标 vtep mac，这会导致在目标节点的第 2 层丢弃所有跨节点流量</p><p>原因： mac 地址被更改了两次，第一次由 flannel 更改，第二次由 systemd 根据其默认策略更改为不同的地址</p><p>解决办法：</p><pre class="line-numbers language-none"><code class="language-none">cat&lt;&lt;'EOF'&gt;/etc/systemd/network/10-flannel.link[Match]OriginalName=flannel*[Link]MACAddressPolicy=noneEOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> cni </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cni </tag>
            
            <tag> flannel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>macvlan</title>
      <link href="/2022/01/12/cni/macvlan/"/>
      <url>/2022/01/12/cni/macvlan/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是macvlan"><a href="#什么是macvlan" class="headerlink" title="什么是macvlan"></a>什么是macvlan</h2><p>macvlan 是将一块以太网卡虚拟成多块以太网卡的一种技术方案。一块以太网卡需要有一个MAC地址，以往，我们使用一块以太网卡也可以配置多个IP地址类似ethx:y，但是他们的MAC地址是一样的。这里本质上还是一块网卡，在二层数据处理上有很多限制（数据链路层物理寻址需要mac地址），所以macvlan技术就出来了。</p><p>macvlan有几种模式，如下</p><ul><li>VEPA macvlan接口出来的流程都发送到父接口，由于生成树协议限制两个子接口之间通讯会给阻塞，需要配置Hairpin支持，也就是源和目的地址都是本地 Macvlan 接口地址的流量发回给相应的接口，所以需要交换机设备支持，无法配置交换机情况下也可以使用网桥代替交换机，将网卡设备放置到网桥中，再让网桥启动hairpin，如<code>brctl hairpin br0 eth1 on</code></li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234221.png" alt="preview"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234709.png" alt="在这里插入图片描述"></p><ul><li>Private     和VEPA模式类似，但其完全阻止共享同一父接口的 Macvlan 虚拟网卡之间的通讯，即使配置了 <code>Hairpin</code> 让从父接口发出的流量返回到宿主机，相应的通讯流量依然被丢弃。</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234291.jpg" alt="img"></p><ul><li><p>Bridge    和linux上网桥类似，子网卡之间数据可以相互通讯。但是不需要mac地址学习，也不需要STP（生成树协议），效率比网桥高，但是父接口down会导致子接口全部down，从而无法通讯。（所以生产环境使用bond网卡作为父接口）</p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234373.jpg" alt="img"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234027.png" alt="在这里插入图片描述"></p></li><li><p>Passthru    每个父接口只能和一个 Macvlan 虚拟网卡接口进行捆绑，并且 Macvlan 虚拟网卡接口继承父接口的 MAC 地址。此种模式的优点是虚拟机和容器可以更改 MAC 地址和其它一些接口参数。</p></li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234335.jpg" alt="img"></p><p>我们使用的是Bridge模式，</p><p>缺点：</p><ul><li>父网卡和子网卡无法通讯（看下图）</li><li>由于802.11无法识别一块网卡多个MAC地址，则无线环境下无法通讯</li><li>物理网卡对MAC地址数量过大导致性能影响问题</li><li>交换机面对同一网卡内MAC地址数量过大影响性能问题</li><li>交换机MAC地址限制问题</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234017.png" alt="img"></p><p>物理网卡也就相当于一个交换机，记录着对应的虚拟网卡和 MAC 地址，当物理网卡收到数据包后，会根据目的 MAC 地址判断这个包属于哪一个虚拟网卡。这也就意味着，只要是从 Macvlan 子接口发来的数据包（或者是发往 Macvlan 子接口的数据包），物理网卡只接收数据包，不处理数据包，所以这就引出了一个问题：本机 Macvlan 网卡上面的 IP 无法和物理网卡上面的 IP 通信！</p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202203251234842.jpg" alt="img"></p><h3 id="macvlan和bridge区别"><a href="#macvlan和bridge区别" class="headerlink" title="macvlan和bridge区别"></a>macvlan和bridge区别</h3><blockquote><p>Macvlan</p></blockquote><ul><li>仅仅需要为虚拟机或容器提供访问外部物理网络的连接。</li><li>Macvlan 占用较少的 CPU，同时提供较高的吞吐量。</li><li>宿主机无法和 VM 或容器直接进行通讯。</li></ul><blockquote><p>Bridge</p></blockquote><ul><li>需要应用高级流量控制，FDB的维护。</li></ul><blockquote><p>为什么bond可以作为父接口</p></blockquote><h3 id="使用macvlan"><a href="#使用macvlan" class="headerlink" title="使用macvlan"></a>使用macvlan</h3><ul><li>命令</li></ul><pre class="line-numbers language-none"><code class="language-none">ip link add link eth0 name macvlan1 type macvlan mode bridge<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>网卡macvlan配置</li></ul><pre class="line-numbers language-none"><code class="language-none">vim /etc/sysconfig/network-scripts/ifcfg-eth0TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=none#DEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=noNAME=eth0DEVICE=eth0ONBOOT=yescat /etc/sysconfig/network# Created by anacondaif ! ip l show macvlan1 &amp;&gt;/dev/null; then ip l add link eth0 name macvlan1 type macvlan mode bridge ifconfig macvlan1 172.16.123.200/24 fiif ! ip r | grep default &amp;&gt;/dev/null;then ip r add default via 172.16.123.254 dev macvlan1fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>docker</li></ul><pre class="line-numbers language-none"><code class="language-none"># --subnet= "" macvlan设置⽹络docker network create -d macvlan --subnet=172.16.123.0/24 --gateway=172.16.123.254 -o parent=eth1 mac1docker run -itd --name c1 --ip=172.16.123.200 --network mac1 busybox<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li>网络插件cni</li></ul><pre class="line-numbers language-none"><code class="language-none"># /opt/cni/bin/macvlan# cat &gt;/test-cni/macvlan-demo.conf&lt;&lt;EOF{    "cniVersion": "0.3.0",    "type": "macvlan",           # macvlan    "master": "eth0",            # 父接口    "mode": "bridge",            # 模式    "ipam": {          "type": "host-local",          "subnet": "172.16.0.0/16",          "rangeStart": "172.16.123.101",          "rangeEnd": "172.16.123.200",          "routes": [            { "dst": "0.0.0.0/0" }          ],          "gateway": "172.16.0.254"     }}EOFcd /opt/cni/binip netns add macvlan-demoip netns listCNI_COMMAND=ADD CNI_CONTAINERID=macvlan-demo CNI_NETNS=/var/run/netns/macvlan-demo CNI_IFNAME=eth0 CNI_PATH=/opt/cni/bin ./macvlan &lt;/test-cni/macvlan-demo.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="kubernetes如何使用multus创建macvlan网卡"><a href="#kubernetes如何使用multus创建macvlan网卡" class="headerlink" title="kubernetes如何使用multus创建macvlan网卡"></a>kubernetes如何使用multus创建macvlan网卡</h3><ul><li>安装multus</li></ul><pre class="line-numbers language-none"><code class="language-none">- 修改配置文件cncp.yaml- make gen,make cncp#安装010-cni插件#安装040-cert<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>配置</li></ul><pre class="line-numbers language-none"><code class="language-none">cat &lt;&lt;EOF | kubectl create -f -apiVersion: "k8s.cni.cncf.io/v1"kind: NetworkAttachmentDefinitionmetadata:  name: macvlan0  namespace: kube-systemspec:  config: '{    "cniVersion": "0.3.0",    "type": "macvlan",    "master": "eth0",    "mode": "bridge",    "ipam": {          "type": "host-local",          "subnet": "172.16.0.0/16",          "rangeStart": "172.16.123.101",          "rangeEnd": "172.16.123.200",          "routes": [            { "dst": "0.0.0.0/0" }          ],          "gateway": "172.16.0.254"     }  }'EOF# 创建podcat &lt;&lt;EOF | kubectl create -f -apiVersion: v1kind: Podmetadata:  name: macvlan-demo  annotations:    v1.multus-cni.io/default-network: '[{"name":"macvlan0","namespace":"kube-system","ips":["172.16.123.108"]}]'   # 使用上述配置去配置默认网卡指定IPspec:  containers:  - name: macvlan-demo    image: cncp/utils/network-multitool:latestEOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> cni </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cni </tag>
            
            <tag> macvlan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>etcd单点部署</title>
      <link href="/2022/01/12/etcd/etcd-dan-dian-bu-shu/"/>
      <url>/2022/01/12/etcd/etcd-dan-dian-bu-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="etcd单节点部署"><a href="#etcd单节点部署" class="headerlink" title="etcd单节点部署"></a>etcd单节点部署</h1><h2 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h2><pre class="line-numbers language-none"><code class="language-none">mkdir /opt/etcd/bin /var/lib/etcd /opt/etcd/config/ -pwget -O /opt/etcd/etcd-v3.1.5-linux-amd64.tar.gz  https://github.com/coreos/etcd/releases/download/v3.1.5/etcd-v3.1.5-linux-amd64.tar.gzcd /opt/etcd/ &amp;&amp; tar xzvf etcd-v3.1.5-linux-amd64.tar.gzmv etcd* /bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ul><li>配置etcd配置文件</li></ul><pre class="line-numbers language-none"><code class="language-none">cat &lt;&lt;EOF | sudo tee /opt/etcd/config/etcd.conf#节点名称ETCD_NAME=$(hostname -s)#数据存放位置ETCD_DATA_DIR=/var/lib/etcdEOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>配置etcd启动脚本</li></ul><pre class="line-numbers language-none"><code class="language-none">cat &lt;&lt;EOF | sudo tee /etc/systemd/system/etcd.service[Unit]Description=Etcd ServerDocumentation=https://github.com/coreos/etcdAfter=network.target[Service]User=rootType=notifyEnvironmentFile=-/opt/etcd/config/etcd.confExecStart=/opt/etcd/bin/etcdRestart=on-failureRestartSec=10sLimitNOFILE=40000[Install]WantedBy=multi-user.targetEOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>配置环境变量</li></ul><pre class="line-numbers language-none"><code class="language-none">echo PATH=$PATH:/opt/etcd/bin/ &gt;&gt;~/.bash_profilesource ~/.bash_profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>启动etcd</li></ul><pre class="line-numbers language-none"><code class="language-none">systemctl daemon-reload &amp;&amp; systemctl enable etcd &amp;&amp; systemctl start etcd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><pre class="line-numbers language-none"><code class="language-none">etcd --version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="命令使用"><a href="#命令使用" class="headerlink" title="命令使用"></a>命令使用</h2><pre class="line-numbers language-none"><code class="language-none">--debug 输出CURL命令，显示执行命令的时候发起的请求--no-sync 发出请求之前不同步集群信息--output, -o 'simple' 输出内容的格式(simple 为原始信息，json 为进行json格式解码，易读性好一些)--peers, -C 指定集群中的同伴信息，用逗号隔开(默认为: "127.0.0.1:4001")--cert-file HTTPS下客户端使用的SSL证书文件--key-file HTTPS下客户端使用的SSL密钥文件--ca-file 服务端使用HTTPS时，使用CA文件进行验证--help, -h 显示帮助命令信息--version, -v 打印版本信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> etcd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> etcd </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql</title>
      <link href="/2022/01/12/databases/mysql/mysql/"/>
      <url>/2022/01/12/databases/mysql/mysql/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> databases </category>
          
      </categories>
      
      
        <tags>
            
            <tag> databases </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker多个容器共用一个IP地址</title>
      <link href="/2022/01/11/docker-compose/docker-duo-ge-rong-qi-gong-yong-yi-ge-ip-di-zhi/"/>
      <url>/2022/01/11/docker-compose/docker-duo-ge-rong-qi-gong-yong-yi-ge-ip-di-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="如何使用docker-compose实现kubernetes-pod共用IP功能"><a href="#如何使用docker-compose实现kubernetes-pod共用IP功能" class="headerlink" title="如何使用docker-compose实现kubernetes pod共用IP功能"></a>如何使用docker-compose实现kubernetes pod共用IP功能</h1><h2 id="创建docker网络"><a href="#创建docker网络" class="headerlink" title="创建docker网络"></a>创建docker网络</h2><pre class="line-numbers language-none"><code class="language-none">docker network create -d macvlan --subnet=172.16.111.0/16 --gateway=172.16.0.254 -o parent=macvlan0 mac1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="先创建一个容器"><a href="#先创建一个容器" class="headerlink" title="先创建一个容器"></a>先创建一个容器</h2><pre class="line-numbers language-none"><code class="language-none">docker-compose]# docker run -it --name 11  --rm  --ip=172.16.111.150 --network mac1 busybox sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="再创建一个容器"><a href="#再创建一个容器" class="headerlink" title="再创建一个容器"></a>再创建一个容器</h2><pre class="line-numbers language-none"><code class="language-none">docker run -it --name test22  --rm  --network=container:test11  busybox sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="对应执行ip-a测试"><a href="#对应执行ip-a测试" class="headerlink" title="对应执行ip a测试"></a>对应执行<code>ip a</code>测试</h2><pre class="line-numbers language-none"><code class="language-none"># ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever186: eth0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue    link/ether 02:42:ac:10:6f:96 brd ff:ff:ff:ff:ff:ff    inet 172.16.111.150/16 brd 172.16.255.255 scope global eth0       valid_lft forever preferred_lft forever/ #<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ip </tag>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>居于kubeadm部署的etcd备份恢复</title>
      <link href="/2022/01/11/etcd/etcd-bei-fen-hui-fu/"/>
      <url>/2022/01/11/etcd/etcd-bei-fen-hui-fu/</url>
      
        <content type="html"><![CDATA[<h1 id="居于-kubeadm部署的etcd备份恢复"><a href="#居于-kubeadm部署的etcd备份恢复" class="headerlink" title="居于 kubeadm部署的etcd备份恢复"></a>居于 <code>kubeadm</code>部署的etcd备份恢复</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <code>k8s</code>运行过程中难免会遇到 <code>etcd</code>集群异常的情况。我们该如何做到备份以及恢复。</p><table><thead><tr><th>端口</th><th>作用</th></tr></thead><tbody><tr><td>2379</td><td>提供 HTTP API 服务，供客户端交互</td></tr><tr><td>2380</td><td>和集群中其他节点通信</td></tr></tbody></table><h2 id="ETCD-备份"><a href="#ETCD-备份" class="headerlink" title="ETCD 备份"></a>ETCD 备份</h2><pre class="line-numbers language-none"><code class="language-none">ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt  --key=/etc/kubernetes/pki/etcd/server.key --endpoints=https://&lt;IP&gt;:2379 snapshot save ./etcd-snapshot-`date +%Y%m%d`.db<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="ETCD恢复"><a href="#ETCD恢复" class="headerlink" title="ETCD恢复"></a>ETCD恢复</h2><ul><li><p>将备份文件传到所有etcd节点中</p><p>使用 <code>scp</code>拷贝到各个机器·</p></li><li><p>逐台停止 <code>kube-apiserver</code>以及所有 <code>etcd</code>服务</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mv /etc/kubernetes/manifests/{etcd.yaml,kube-apiserver.yaml} /tmp/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>备份etcd数据目录并留空</p><pre class="line-numbers language-none"><code class="language-none">rm -rf /var/lib/etcd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>逐台执行命令去恢复</p><pre class="line-numbers language-none"><code class="language-none">ETCDCTL_API=3 etcdctl snapshot restore ./etcd-snapshot-20211009.db \  --name &lt;HOSTNAME&gt; \#   --initial-cluster "&lt;HOSTNAME&gt;=https://&lt;IP&gt;:2380" \ 单节点则写单个  --initial-cluster "&lt;HOSTNAME&gt;=https://&lt;IP&gt;:2380,&lt;HOSTNAME&gt;=https://&lt;IP&gt;:2380,&lt;HOSTNAME&gt;=https://&lt;IP&gt;:2380" \  --initial-cluster-token etcd-cluster \  --initial-advertise-peer-urls https://&lt;IP&gt;:2380 \ # 集群多个节点则往后太添加《,https://&lt;IP&gt;:2380》  --data-dir=/var/lib/etcd/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>逐台启动启动 <code>api-service</code>以及 <code>etcd</code>服务</p><pre class="line-numbers language-none"><code class="language-none">mv /tmp/{etcd.yaml,kube-apiserver.yaml} /etc/kubernetes/manifests/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>检查etcd集群状态</p><pre class="line-numbers language-none"><code class="language-none">ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt  --key=/etc/kubernetes/pki/etcd/server.key --endpoints=https://&lt;IP&gt;:2379   member list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>kubelet检查</p><pre class="line-numbers language-none"><code class="language-none">kubectl get nodekubectl get cs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><h2 id="ETCD操作"><a href="#ETCD操作" class="headerlink" title="ETCD操作"></a>ETCD操作</h2><ul><li><p>查询健康状态</p><pre class="line-numbers language-none"><code class="language-none">ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt  --key=/etc/kubernetes/pki/etcd/healthcheck-client.key --endpoints=https://&lt;IP&gt;:2379 endpoint health<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>查询所有key</p><pre class="line-numbers language-none"><code class="language-none">ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt  --key=/etc/kubernetes/pki/etcd/server.key --endpoints=https://&lt;IP&gt;:2379 get / --prefix --keys-only<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>查看成员</p><pre class="line-numbers language-none"><code class="language-none">ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt  --key=/etc/kubernetes/pki/etcd/server.key --endpoints=https://&lt;IP&gt;:2379   member list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> etcd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> etcd </tag>
            
            <tag> kubeadm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rook-ceph osd 内存限制</title>
      <link href="/2022/01/11/rook-ceph/rook-ceph-de-osd-nei-cun-xian-zhi/"/>
      <url>/2022/01/11/rook-ceph/rook-ceph-de-osd-nei-cun-xian-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="rook-ceph内存限制"><a href="#rook-ceph内存限制" class="headerlink" title="rook-ceph内存限制"></a>rook-ceph内存限制</h2><blockquote><p>在osd均衡以及大量的数据读情况下，rook-ceph-osd在没有限制情况下会出现内存无限增长</p></blockquote><h3 id="模拟内存增长"><a href="#模拟内存增长" class="headerlink" title="模拟内存增长"></a>模拟内存增长</h3><blockquote><p>数据均衡</p></blockquote><ul><li>关闭osd，模拟osd异常，数据进行均衡</li></ul><pre class="line-numbers language-none"><code class="language-none">ceph osd set noupceph osd down &lt;id&gt;# 模拟完成后关闭ceph osd unset noup<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li>启动数据均衡</li></ul><pre class="line-numbers language-none"><code class="language-none">ceph  balancer onceph  balancer status# 模拟完成后关闭ceph  balancer off<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>压测数据读</p></blockquote><ul><li>压测模拟</li></ul><pre class="line-numbers language-none"><code class="language-none">rados bench -p bigstorage 2000 write -t 60 --run-name  client1 no-cleanuprados bench -p bigstorage 2000 rand --run-name client1# 模拟完成后删除压测数据rados -p bigstorage cleanup --prefix benchmark_data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="内存数据分析"><a href="#内存数据分析" class="headerlink" title="内存数据分析"></a>内存数据分析</h3><pre class="line-numbers language-none"><code class="language-none">ceph tell osd.&lt;id&gt; heap start_profilerceph tell osd.&lt;id&gt; heap dump# 关闭内存分析ceph tell osd.&lt;id&gt; heap stop_profiler<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111855304.png" alt="image-20211215104016153"></p><h3 id="内存限制"><a href="#内存限制" class="headerlink" title="内存限制"></a>内存限制</h3><blockquote><p>官方推荐osd内存占用最小推荐为<code>3GB</code>,每增涨1TB则新增<code>1GB</code>内存</p></blockquote><pre class="line-numbers language-none"><code class="language-none"># 命令行实现ceph config set osd.&lt;id&gt; osd_memory_target 5368709120# for i in `seq 0 &lt;NUM&gt;`;do ceph config set osd.$i osd_memory_target 5368709120;done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><pre class="line-numbers language-none"><code class="language-none"># 观察内存变化kubectl  top pod -A -l  app=rook-ceph-osd --sort-by='memory'# 查看设置是否成功ceph config get osd.&lt;id&gt; osd_memory_target# 查看配置ceph config dump<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="部分截图"><a href="#部分截图" class="headerlink" title="部分截图"></a>部分截图</h3><blockquote><p>如下图，<code>osd2</code>以及<code>osd6</code>设置了内存限制，此时观察发现<code>osd2</code>以及<code>osd6</code>限制为<code>5GB</code>以内</p></blockquote><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111855375.png" alt="image-20211215110201700"></p><blockquote><p>如何确保内存限制成功呢</p></blockquote><p>使用实验对照组进行测试，将<code>osd.2</code>或者<code>osd.6</code>的限制进行删除，再执行《模拟内存增长》，⚠️多次测试</p><pre class="line-numbers language-none"><code class="language-none">ceph config rm osd.&lt;id&gt; osd_memory_target<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111855612.png" alt="image-20211215111332077"></p>]]></content>
      
      
      <categories>
          
          <category> rook-ceph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rook-ceph </tag>
            
            <tag> 优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k8s 通过helm部署gitlab-runner</title>
      <link href="/2022/01/11/cicd/k8s-tong-guo-helm-bu-shu-gitlab-runner/"/>
      <url>/2022/01/11/cicd/k8s-tong-guo-helm-bu-shu-gitlab-runner/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h1 id="gitlab-需要提供的参数-URL-TOKEN"><a href="#gitlab-需要提供的参数-URL-TOKEN" class="headerlink" title="gitlab 需要提供的参数 URL+TOKEN"></a>gitlab 需要提供的参数 URL+TOKEN</h1><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/cicd/202201121334232.png" alt="gitlab-runner 需要参数"></p><h1 id="部署相关"><a href="#部署相关" class="headerlink" title="部署相关"></a>部署相关</h1><h2 id="安装helm"><a href="#安装helm" class="headerlink" title="安装helm"></a>安装helm</h2><p><a href="https://www.jianshu.com/p/9f294f654433">安装helm安装部署参考</a></p><h2 id="通过helm安装gitlab-runner"><a href="#通过helm安装gitlab-runner" class="headerlink" title="通过helm安装gitlab-runner"></a>通过helm安装gitlab-runner</h2><blockquote><p>下载gitlab-runner</p></blockquote><pre class="line-numbers language-none"><code class="language-none">git clone https://github.com/haoshuwei/ack-gitlab-runner.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>修改文件values.yaml</p></blockquote><pre class="line-numbers language-none"><code class="language-none">gitlabUrl: gitlab服务器上管理页面上的URLrunnerRegistrationToken: gitlab服务器管理页面的token<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><blockquote><p>现在直接打包部署会出现报错</p></blockquote><ul><li><a href="https://www.jianshu.com/p/21d916643560">解决办法参考</a></li><li>修改配置文件<pre class="line-numbers language-none"><code class="language-none">vim templates/deployment.yamlapiVersion: apps/v1                                        # 修改kind: Deploymentmetadata:  name: {{ template "gitlab-runner.fullname" . }}  labels:    app: {{ template "gitlab-runner.fullname" . }}    chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"    release: "{{ .Release.Name }}"    heritage: "{{ .Release.Service }}"spec:  replicas: 1  selector:                                                             # 新增加    matchLabels:                                                   # 新增加      app: gitlab-runner-ack-gitlab-runner             # 新增加<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>如何使用pvc</p></blockquote></li><li>搭建nfs<br><a href="https://www.jianshu.com/p/8dc6ba8d34b1">搭建nfs</a></li><li>创建pv</li></ul><pre class="line-numbers language-none"><code class="language-none">vim pv-nfs.confapiVersion: v1kind: PersistentVolumemetadata:  name: nfs-pv  labels:spec:  nfs:    path: /mnt/jamestest    server: 192.168.0.252  accessModes: ["ReadWriteMany","ReadWriteOnce"]  capacity:    storage: 100Gi# 创建pvkubectl apply -f pv-nfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>修改ack-gitlab-runner中的pvc</p><pre class="line-numbers language-none"><code class="language-none">apiVersion: v1kind: PersistentVolumeClaimmetadata:  labels:    app: {{ template "gitlab-runner.fullname" . }}  name: gitlab-runner-cachespec:  accessModes:  - ReadWriteOnce  resources:    requests:      storage: 20Gi  selector:    matchLablel:      app: nfs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>nfs类型pvc使用常见问题<br><a href="https://www.jianshu.com/p/175402cd5d3d">常见问题</a></p></li></ul><blockquote><p>打包部</p></blockquote><ul><li>打包部署<pre class="line-numbers language-none"><code class="language-none"># helm 打包helm package .# 安装helm打包文件helm install --namespace gitlab --name gitlab-runner *.tgz# 查看安装是否成功helm list<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>helm 删除<pre class="line-numbers language-none"><code class="language-none"># 删除已安装的包helm del --purge gitlab-runner<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h2><blockquote><p>检查gitlab 管理页面是否出现该runner<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/cicd/202201121334508.png" alt="出现刚刚注册的runner"></p></blockquote></li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://help.aliyun.com/document_detail/106968.html">gitlab-runner安装</a></p><ul><li><a href="https://www.jianshu.com/p/1014b0ec876d">非dockers安装gitlab-runner</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> cicd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> cicd </tag>
            
            <tag> gitlab </tag>
            
            <tag> gitlab-runner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gitlab+newman实现自动化测试</title>
      <link href="/2022/01/11/cicd/gitlab-newman-shi-xian-zi-dong-hua-ce-shi/"/>
      <url>/2022/01/11/cicd/gitlab-newman-shi-xian-zi-dong-hua-ce-shi/</url>
      
        <content type="html"><![CDATA[<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><pre class="line-numbers language-none"><code class="language-none">npm install -g newmannpm install -g newman-reporter-htmlnewman run examples/sample-collection.jsonnewman run examples/sample-collection.json -r html# 生产报告在当前的目录下的newman内<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="结果截图"><a href="#结果截图" class="headerlink" title="结果截图"></a>结果截图</h1><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121203986.png" alt="生成的报告"></p><h1 id="易错点"><a href="#易错点" class="headerlink" title="易错点"></a>易错点</h1><blockquote><p>安装newman-reporter-html错误</p></blockquote><pre class="line-numbers language-none"><code class="language-none">[root@test2 sendEmail]# newman run scripts/web.postman_collection.json  -r htmlnewman: "html" reporter could not be loaded.  run `npm install newman-reporter-html`[root@test2 sendEmail]# npm install newman-reporter-htmlnpm WARN saveError ENOENT: no such file or directory, open '/SHELL/autoTest/sendEmail/package.json'npm notice created a lockfile as package-lock.json. You should commit this file.npm WARN enoent ENOENT: no such file or directory, open '/SHELL/autoTest/sendEmail/package.json'npm WARN newman-reporter-html@1.0.3 requires a peer of newman@4 but none is installed. You must install peer dependencies yourself.npm WARN sendEmail No descriptionnpm WARN sendEmail No repository field.npm WARN sendEmail No README datanpm WARN sendEmail No license field.+ newman-reporter-html@1.0.3added 13 packages from 45 contributors and audited 14 packages in 1.615sfound 1 high severity vulnerability  run `npm audit fix` to fix them, or `npm audit` for details[root@test2 sendEmail]# npm audit fixnpm ERR! code EAUDITNOPJSONnpm ERR! audit No package.json found: Cannot audit a project without a package.jsonnpm ERR! A complete log of this run can be found in:npm ERR!     /root/.npm/_logs/2019-07-18T08_27_23_701Z-debug.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>问题截图<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121203417.png" alt="生产报告安装newman-reporter-html报错"></p></li><li><p>解决办法</p><pre class="line-numbers language-none"><code class="language-none">npm install -g newman-reporter-html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://www.npmjs.com/package/newman">参考文档</a></p>]]></content>
      
      
      <categories>
          
          <category> cicd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cicd </tag>
            
            <tag> newman </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sonar+sonar-scanner+gitlab+gitlab-runner实现代码的检测、部署以及通知</title>
      <link href="/2022/01/10/cicd/sonar-sonar-scanner-gitlab-gitlab-runner-shi-xian-dai-ma-de-jian-ce-bu-shu-yi-ji-tong-zhi/"/>
      <url>/2022/01/10/cicd/sonar-sonar-scanner-gitlab-gitlab-runner-shi-xian-dai-ma-de-jian-ce-bu-shu-yi-ji-tong-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>随着工作量越来越大，我们需要保证我们的工作效率的同时保证我们的代码的质量，所以我们需要一些自动化的东西加入到我们的工作中<br>自动化部署、自动化测试、自动化通知等。</p><h1 id="文章内容"><a href="#文章内容" class="headerlink" title="文章内容"></a>文章内容</h1><p>改文章主要简述如何通过sonar进行代码检测<br>如何实现自动部署和自动检测将在下一篇中简述</p><h1 id="什么是sonar"><a href="#什么是sonar" class="headerlink" title="什么是sonar"></a>什么是sonar</h1><p><a href="https://www.sonarqube.org/">官网地址</a><br>sonar实现对静态代码的扫描，给我对代码质量、安全的解析</p><h1 id="需要实现功能"><a href="#需要实现功能" class="headerlink" title="需要实现功能"></a>需要实现功能</h1><ul><li>一台centos7 服务器<ul><li>安装gitlab</li><li>安装sonar</li><li>安装sonar数据库</li></ul></li><li>一台客户端服务器<ul><li>安装gitlab-runner</li><li>安装sonar-scanner</li><li>安装构建java的maven</li></ul></li><li>实现功能，通过gitlab推送代码到gitlab服务器，gitlab通过gitlab-runner实现触发，通过.gitlab-ci.yml控制触发后流程，再流程中通过脚本实现对代码的检测，对代码的构建，对代码的部署，对部署结果的通知到企业微信。<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149889.png" alt="实现结果图"></li></ul><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><ul><li>sonarqube-7.9就不支持mysql</li></ul><blockquote><p>下载sonar</p></blockquote><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-7.8.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>创建数据库</p></blockquote><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 编写docker-compose.ymlvim docker-compose.yml version: '3.3'services:  sonarqube_mysql:    environment:        MYSQL_ROOT_PASSWORD: 123456    image: mysql:5.7    restart: always    volumes:        - /ENV/mysql/sonarqube/mysql/data/:/var/lib/mysql/        - /ENV/mysql/sonarqube/mysql/conf/:/etc/mysql/    ports:        - 3306:3306    container_name: sonarqube_mysql    # 创建对应目录并启动mkdir /ENV/mysql/sonarqube/mysql/{data,conf} -pdocker-compose up -d# 连接上mysql创建数据库sonarcreate database sonar default character set utf8 collate utf8_general_ci;# 授权grant all on sonar.* to sonar@'%' identified by '123456';<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>编辑配置文件</p></blockquote><pre class="line-numbers language-none"><code class="language-none">vim sonar.propertiessonar.jdbc.username=sonarsonar.jdbc.password=123456sonar.jdbc.url=jdbc:mysql://192.168.0.71:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false&lt; sonar.host.url &gt;http://192.168.0.71:9000&lt;/ sonar.host.url &gt; &lt;!-- Sonar服务器访问地址 --&gt;sonar.login=adminsonar.password=adminsonar.web.host=0.0.0.0sonar.web.port=9000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>启动进入web打开URL:9000</p></blockquote><pre class="line-numbers language-none"><code class="language-none">su sonar ./sonar.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>安装sonar-scan</p></blockquote><ul><li>下载sonar-scanner-cli-4.0.0.1744-linux.zip<pre class="line-numbers language-none"><code class="language-none"># 页面地址https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/# 下载地址wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.0.0.1744-linux.zip<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li>解压<pre class="line-numbers language-none"><code class="language-none">unzip sonar-scanner-cli-4.0.0.1744-linux.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>配置PATH</li></ul><pre class="line-numbers language-none"><code class="language-none">ln -s sonar-scanner-cli-4.0.0.1744-linux sonar-scannervim /etc/profileexport PATH=$PATH:/INSTALL/sonar/PATH/sonar-scanner/binsource /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><hr><blockquote><p>扫描java</p></blockquote><ul><li>服务端页面创建项目<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149330.png" alt="点击+创建项目"></li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149740.png" alt="输入项目名字"><br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149221.png" alt="得到token"><br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149687.png" alt="得到token"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149519.png" alt="image.png"></p><ul><li>服务器上运行<pre class="line-numbers language-none"><code class="language-none"># 需要加最后一行，否则会报错mvn sonar:sonar \  -Dsonar.projectKey=test_java \  -Dsonar.host.url=http://192.168.0.71:9000 \  -Dsonar.login=d003e898d6a34d0db25b255cbbe66a6bd771c746  -Dsonar.java.binaries=target/sonar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>页面刷新可以看到报告<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149989.png" alt="生成报告页面"></li></ul><blockquote><p>扫描前端（h5,js等）</p></blockquote><ul><li>创建项目<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149197.png" alt="创建项目"></li><li>生成token<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149587.png" alt="生成token"></li><li>得到服务器运行命令<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149932.png" alt="得到命令"><blockquote><p>服务器运行</p></blockquote><pre class="line-numbers language-none"><code class="language-none">sonar-scanner \  -Dsonar.projectKey=test_web \  -Dsonar.sources=. \  -Dsonar.host.url=http://192.168.0.71:9000 \  -Dsonar.login=06992092bbd9e25758f2b5d047bea4027d46824c<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>生成报告<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149652.png" alt="生成报告"></li></ul><hr><blockquote><p>配置中文模块</p></blockquote><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149711.png" alt="配置中文"><br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149048.png" alt="安装成功，重启服务"></p><ul><li>需要5分钟后刷新看结果<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149354.png" alt="安装中文包成功"></li></ul><h1 id="sonar-连接gitlab"><a href="#sonar-连接gitlab" class="headerlink" title="sonar 连接gitlab"></a>sonar 连接gitlab</h1><ul><li>下载gitlab插件<br><a href="https://github.com/gabrie-allaigre/sonar-gitlab-plugin/releases">https://github.com/gabrie-allaigre/sonar-gitlab-plugin/releases</a><pre class="line-numbers language-none"><code class="language-none">wget https://github.com/gabrie-allaigre/sonar-gitlab-plugin/releases/download/3.0.2/sonar-gitlab-plugin-3.0.2.jarcp sonar-gitlab-plugin-3.0.2.jar  &lt;sonarqube_install_dir&gt;/extensions/plugins# 重启sonar# 应用市场安装gitlab相关的插件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149928.png" alt="安装插件"></li></ul><blockquote><p>配置连接gitlab用户</p></blockquote><ul><li>创建gitlab用户，略</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149609.png" alt="创建tokens"></p><blockquote><p>配置sonar<br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149248.png" alt="配置sonar中的gitlab"></p></blockquote><blockquote></blockquote><hr><h1 id="常见报错"><a href="#常见报错" class="headerlink" title="常见报错"></a>常见报错</h1><blockquote><p>sonar 应为java版本问题</p></blockquote><ul><li><p>报错日志</p><pre class="line-numbers language-none"><code class="language-none">--&gt; Wrapper Started as DaemonLaunching a JVM...Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.org  Copyright 1999-2006 Tanuki Software, Inc.  All Rights Reserved.WrapperSimpleApp: Encountered an error running main: java.lang.IllegalStateException: SonarQube requires Java 11+ to runjava.lang.IllegalStateException: SonarQube requires Java 11+ to run        at org.sonar.application.App.checkJavaVersion(App.java:93)        at org.sonar.application.App.start(App.java:56)        at org.sonar.application.App.main(App.java:98)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:498)        at org.tanukisoftware.wrapper.WrapperSimpleApp.run(WrapperSimpleApp.java:240)        at java.lang.Thread.run(Thread.java:748)&lt;-- Wrapper Stopped<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>解决办法</p><pre class="line-numbers language-none"><code class="language-none"># 重新下载javahttps://www.oracle.com/technetwork/java/javase/downloads/jdk11-downloads-5066655.html# 配置java虚拟环境则可以# 查看版本java -versionjava version "11.0.4" 2019-07-16 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.4+10-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.4+10-LTS, mixed mode)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>日志报错</p><pre class="line-numbers language-none"><code class="language-none">2019.07.25 11:14:22 WARN  app[][o.s.a.p.AbstractManagedProcess] Process exited with exit value [es]: 12019.07.25 11:14:22 INFO  app[][o.s.a.SchedulerImpl] Process[es] is stopped2019.07.25 11:14:22 INFO  app[][o.s.a.SchedulerImpl] SonarQube is stopped&lt;-- Wrapper Stopped<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">2019.07.25 11:22:29 ERROR es[][o.e.b.Bootstrap] Exceptionjava.lang.RuntimeException: can not run elasticsearch as rootat org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:103) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:170) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:333) [elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) [elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:150) [elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) [elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) [elasticsearch-cli-6.8.0.jar:6.8.0]at org.elasticsearch.cli.Command.main(Command.java:90) [elasticsearch-cli-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:116) [elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:93) [elasticsearch-6.8.0.jar:6.8.0]2019.07.25 11:22:29 WARN  es[][o.e.b.ElasticsearchUncaughtExceptionHandler] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as rootat org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:163) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:150) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-6.8.0.jar:6.8.0]at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:116) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:93) ~[elasticsearch-6.8.0.jar:6.8.0]Caused by: java.lang.RuntimeException: can not run elasticsearch as rootat org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:103) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:170) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:333) ~[elasticsearch-6.8.0.jar:6.8.0]at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) ~[elasticsearch-6.8.0.jar:6.8.0]... 6 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>解决办法</p><pre class="line-numbers language-none"><code class="language-none"># 使用非root启动su sonar ./bin/linux-x86-64/sonar.sh status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>elasticsearch process is too low日志报错</p><pre class="line-numbers language-none"><code class="language-none">[root@test2 logs]# tailf es.log 2019.07.25 11:26:25 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}2019.07.25 11:26:25 INFO  es[][o.e.b.BootstrapChecks] explicitly enforcing bootstrap checks2019.07.25 11:26:25 ERROR es[][o.e.b.Bootstrap] node validation exception[2] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]2019.07.25 11:26:25 INFO  es[][o.e.n.Node] stopping ...2019.07.25 11:26:26 INFO  es[][o.e.n.Node] stopped2019.07.25 11:26:26 INFO  es[][o.e.n.Node] closing ...2019.07.25 11:26:26 INFO  es[][o.e.n.Node] closed<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>解决办法</p><pre class="line-numbers language-none"><code class="language-none">vim /etc/security/limits.confsonar hard nofile 65536sonar soft nofile 65536<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>没有报错，但是无法启动</p><pre class="line-numbers language-none"><code class="language-none">2019.07.25 12:03:21 INFO  app[][o.s.a.SchedulerImpl] Process[es] is up2019.07.25 12:03:21 INFO  app[][o.s.a.ProcessLauncherImpl] Launch process[[key='web', ipcIndex=2, logFilenamePrefix=web]] from [/ENV/SonarQube/sonarqube-7.9.1]: /usr/local/jdk-11.0.4/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/ENV/SonarQube/sonarqube-7.9.1/temp --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED -Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Dhttp.nonProxyHosts=localhost|127.*|[::1] -cp ./lib/common/*:/ENV/SonarQube/sonarqube-7.9.1/lib/jdbc/mysql/mysql-connector-java-5.1.46.jar org.sonar.server.app.WebServer /ENV/SonarQube/sonarqube-7.9.1/temp/sq-process6136915182525445856properties2019.07.25 12:03:26 INFO  app[][o.s.a.SchedulerImpl] Process[web] is stopped2019.07.25 12:03:26 INFO  app[][o.s.a.SchedulerImpl] Process[es] is stopped2019.07.25 12:03:26 WARN  app[][o.s.a.p.AbstractManagedProcess] Process exited with exit value [es]: 1432019.07.25 12:03:26 INFO  app[][o.s.a.SchedulerImpl] SonarQube is stopped&lt;-- Wrapper Stopped<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">2019.07.25 13:48:36 ERROR web[][o.s.s.p.Platform] Web server startup failed: ##############################################################################################################         End of Life of MySQL Support : SonarQube 7.9 and future versions do not support MySQL.            ##         Please migrate to a supported database. Get more details at                                       ##         https://community.sonarsource.com/t/end-of-life-of-mysql-support                                  ##         and https://github.com/SonarSource/mysql-migrator                                                 ##############################################################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>解决办法<br><a href="https://github.com/SonarSource/mysql-migrator">参考文档</a><br><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201121149769.png" alt="不支持mysql"><br><a href="https://jira.sonarsource.com/browse/SONAR-12251">官方说明不支持mysql</a></p></li><li><p>错误日志</p><pre class="line-numbers language-none"><code class="language-none">jvm 1    | ERROR: [1] bootstrap checks failedjvm 1    | [1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]jvm 1    | 2019.07.26 22:40:45 WARN  app[][o.s.a.p.AbstractManagedProcess] Process exited with exit value [es]: 78jvm 1    | 2019.07.26 22:40:45 INFO  app[][o.s.a.SchedulerImpl] Process[es] is stoppedjvm 1    | 2019.07.26 22:40:45 INFO  app[][o.s.a.SchedulerImpl] SonarQube is stopped<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>解决办法</p><pre class="line-numbers language-none"><code class="language-none">vim /etc/sysctl.confvm.max_map_count=655360sysctl -p<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>错误日志</p><pre class="line-numbers language-none"><code class="language-none">Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.4+10-LTS, mixed mode)[root@test2 ldd-XXX]# mvn sonar:sonar \&gt;   -Dsonar.projectKey=ldd-attendance \&gt;   -Dsonar.host.url=http://192.168.0.71:9000 \&gt;   -Dsonar.login=5f276ec558029a844a4122813d5cda748fdxxxx[INFO] 1 source files to be analyzed[INFO] Sensor XML Sensor [xml] (done) | time=11ms[INFO] 1/1 source files have been analyzed[INFO] ------------- Run sensors on module front-end[INFO] Sensor JavaSquidSensor [java][INFO] Configured Java source version (sonar.java.source): 8[INFO] JavaClasspath initialization[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary for laodeduo 0.0.1-SNAPSHOT:[INFO] [INFO] laodeduo ........................................... FAILURE [ 14.021 s][INFO] model-util ......................................... SKIPPED[INFO] common-base ........................................ SKIPPED[INFO] front-end .......................................... SKIPPED[INFO] back-end ........................................... SKIPPED[INFO] authe-autho ........................................ SKIPPED[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time:  15.581 s[INFO] Finished at: 2019-07-29T18:46:21+08:00[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.sonarsource.scanner.maven:sonar-maven-plugin:3.6.0.1398:sonar (default-cli) on project laodeduo: Please provide compiled classes of your project with sonar.java.binaries property -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>解决办法</p><pre class="line-numbers language-none"><code class="language-none"># 加上   -Dsonar.java.binaries=target/sonar mvn sonar:sonar   \   -Dsonar.projectKey=java  \   -Dsonar.host.url=http://192.168.0.71:9000  \   -Dsonar.login=8006f416e06dc8b16fbc32763741cc0d9414xxxx \   -Dsonar.java.binaries=target/sonar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> cicd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> cicd </tag>
            
            <tag> gitlab </tag>
            
            <tag> gitlab-runner </tag>
            
            <tag> sonar+sonar </tag>
            
            <tag> scanner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rook-ceph下线osd</title>
      <link href="/2022/01/07/rook-ceph/rook-ceph-yi-chu-osd/"/>
      <url>/2022/01/07/rook-ceph/rook-ceph-yi-chu-osd/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>现在有需求需要停止<code>172-17-27-77</code>上的<code>sda</code>也就是<code>osd0</code></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111718099.png" alt="image-20211203131608704"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111718595.png" alt="image-20211203131633866"></p><h2 id="如何查找对应的osd和磁盘关系"><a href="#如何查找对应的osd和磁盘关系" class="headerlink" title="## 如何查找对应的osd和磁盘关系"></a>## 如何查找对应的osd和磁盘关系</h2><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ul><li><p>先把operator设置为0</p><pre class="line-numbers language-none"><code class="language-none">kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111718630.png" alt="image-20211203131753375"></p></li><li><p>修改配置，将需要移除的盘移除：</p><pre class="line-numbers language-none"><code class="language-none">kubectl edit cephclusters.ceph.rook.io -n rook-ceph   rook-ceph<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>删除对应的对应的盘，如只有一款盘则直接删除主机则圈起来部分</p><p>⚠️如果是该主机下多块盘则删除对应的盘即可，则sda</p><p>当前截图情况删除圈起来部分</p></blockquote><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111718816.png" alt="image-20211203131934027"></p></li><li><p>登陆到<code>toolbox pod</code>内手动移除对应的<code>osd</code>：</p><pre class="line-numbers language-none"><code class="language-none">kubectl exec -it  -n rook-ceph      rook-ceph-tools-769bdf4bdd-hdx6r bash ceph osd set noupceph osd down 0ceph osd out 0 # 等待数据均衡完成<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111718053.png" alt="image-20211203132613145"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111718386.png" alt="image-20211203132635520"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111719261.png" alt="image-20211203132658631"></p></li></ul><h1 id="均衡数据完成后移除对应的osd"><a href="#均衡数据完成后移除对应的osd" class="headerlink" title="均衡数据完成后移除对应的osd"></a>均衡数据完成后移除对应的osd</h1><pre class="line-numbers language-none"><code class="language-none">ceph osd purge 0 --yes-i-really-mean-itceph auth del osd.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111719577.png" alt="image-20211203165153751"></p><h1 id="如果该主机只有一块盘则对应移除该主机"><a href="#如果该主机只有一块盘则对应移除该主机" class="headerlink" title="如果该主机只有一块盘则对应移除该主机"></a>如果该主机只有一块盘则对应移除该主机</h1><blockquote><p>⚠️可以通过<code>ceph osd tree</code>确定该主机是否为一块盘</p></blockquote><pre class="line-numbers language-none"><code class="language-none">ceph osd crush remove 172-17-27-77<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111719009.png" alt="image-20211203165123961"></p><h1 id="检查ceph状态以及osd状态"><a href="#检查ceph状态以及osd状态" class="headerlink" title="检查ceph状态以及osd状态"></a>检查ceph状态以及osd状态</h1><pre class="line-numbers language-none"><code class="language-none">ceph -sceph osd tree<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="移除pod，和判断删除对应的job"><a href="#移除pod，和判断删除对应的job" class="headerlink" title="移除pod，和判断删除对应的job"></a>移除pod，和判断删除对应的job</h1><pre class="line-numbers language-none"><code class="language-none">kubectl delete deploy -n rook-ceph rook-ceph-osd-0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="恢复配置"><a href="#恢复配置" class="headerlink" title="恢复配置"></a>恢复配置</h2><pre class="line-numbers language-none"><code class="language-none">ceph osd unset noup<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="恢复rook的operator"><a href="#恢复rook的operator" class="headerlink" title="恢复rook的operator"></a>恢复rook的operator</h2><pre class="line-numbers language-none"><code class="language-none">kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="检查对应osd的pod是否启动"><a href="#检查对应osd的pod是否启动" class="headerlink" title="检查对应osd的pod是否启动"></a>检查对应osd的pod是否启动</h2><pre class="line-numbers language-none"><code class="language-none">kubectl get pod  -n rook-ceph      -l  app=rook-ceph-osd -o wide<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111719475.png" alt="image-20211203171055644"></p>]]></content>
      
      
      <categories>
          
          <category> rook-ceph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> rook-ceph </tag>
            
            <tag> csi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rook-ceph升级</title>
      <link href="/2022/01/07/rook-ceph/rook-ceph-sheng-ji/"/>
      <url>/2022/01/07/rook-ceph/rook-ceph-sheng-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="rook-ceph升级"><a href="#rook-ceph升级" class="headerlink" title="rook-ceph升级"></a>rook-ceph升级</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于<code>rook-ceph</code>在<code>v1.4.9</code>版本无法配置<code>osd</code>的日志盘，需要升级到<code>v1.5.11    </code></p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>升级前存储必须要是正常状态</li><li>升级前需要做充分模拟以及演练</li><li>升级前做好对应的规划</li><li>出厂设置后变更配置文件或者其他则需要先修改再执行</li><li>升级过程中会伴随osd的多次重启</li></ul><blockquote><p>下面为官方升级建议</p></blockquote><ul><li><strong>警告</strong>：升级<code> Rook</code> 集群并非没有风险。可能存在会损害存储集群完整性和健康状况的意外问题或障碍，包括数据丢失。</li><li><code> Rook operater</code>  更新和 <code>ceph</code> 版本更新的升级过程中，<code>Rook</code> 集群的存储可能会在短时间内不可用。</li><li>我们建议您在进行 <code>Rook </code>集群升级之前完整阅读本文档。</li></ul><h2 id="rook-v1-4-9升级到v1-5-11"><a href="#rook-v1-4-9升级到v1-5-11" class="headerlink" title="rook v1.4.9升级到v1.5.11"></a>rook v1.4.9升级到v1.5.11</h2><h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><blockquote><p>后续都在执行该环境变量终端下执行操作</p></blockquote><pre class="line-numbers language-none"><code class="language-none">export ROOK_OPERATOR_NAMESPACE="rook-ceph"export ROOK_CLUSTER_NAMESPACE="rook-ceph"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="升级前环境健康检查"><a href="#升级前环境健康检查" class="headerlink" title="升级前环境健康检查"></a>升级前环境健康检查</h3><blockquote><p>若检查不通过，需要先解决对应的问题并检查通过方可继续升级</p></blockquote><ul><li><p>集群应该处于具有完整功能的健康状态</p><ol><li><code>osd-prepare</code>为<code>Completed</code>状态，其余所有<code>pods</code>都为<code>Running</code>状态，如下图</li></ol><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE get pods<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/rook202201111657919.png" alt="image-20220111165757742"></p><ol start="2"><li>Ceph集群状态查询</li></ol><blockquote><ul><li>集群健康：整体集群状态是<code>HEALTH_OK</code>，没有显示警告或错误状态消息。</li><li>监视器（mon）：所有监视器都包含在<code>quorum</code>列表中。</li><li>管理器（mgr）：Ceph 管理器处于<code>active</code>状态。</li><li>OSD (osd)：所有 OSD 都是<code>up</code>和<code>in</code>。</li><li>归置组 (pgs)：所有 PG 都在<code>active+clean</code>状态中。</li></ul></blockquote><pre class="line-numbers language-none"><code class="language-none">TOOLS_POD=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111659035.png" alt="image-20220111165925844"></p><ol start="3"><li>容器版本</li></ol><pre class="line-numbers language-none"><code class="language-none">POD_NAME=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -o custom-columns=name:.metadata.name --no-headers | grep rook-ceph-mon-b)kubectl -n $ROOK_CLUSTER_NAMESPACE get pod ${POD_NAME} -o jsonpath='{.spec.containers[0].image}'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111700581.png" alt="image-20211222180142138"></p><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_OPERATOR_NAMESPACE get pod -o jsonpath='{range .items[*]}{.metadata.name}{"\n\t"}{.status.phase}{"\t\t"}{.spec.containers[0].image}{"\t"}{.spec.initContainers[0]}{"\n"}{end}' &amp;&amp; \kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -o jsonpath='{range .items[*]}{.metadata.name}{"\n\t"}{.status.phase}{"\t\t"}{.spec.containers[0].image}{"\t"}{.spec.initContainers[0].image}{"\n"}{end}'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111701372.png" alt="image-20211222180223673"></p><ol start="4"><li>rook版本</li></ol><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE get deployments -o jsonpath='{range .items[*]}{.metadata.name}{"  \treq/upd/avl: "}{.spec.replicas}{"/"}{.status.updatedReplicas}{"/"}{.status.readyReplicas}{"  \trook-version="}{.metadata.labels.rook-version}{"\n"}{end}'kubectl -n $ROOK_CLUSTER_NAMESPACE get jobs -o jsonpath='{range .items[*]}{.metadata.name}{"  \tsucceeded: "}{.status.succeeded}{"      \trook-version="}{.metadata.labels.rook-version}{"\n"}{end}'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111702159.png" alt="image-20211222180303235"></p></li><li><p>所有消耗 Rook 存储的 Pod 都应该被创建、运行并处于稳定状态</p></li></ul><blockquote><p>晚上升级，保障数据写入以及pod的变动少</p></blockquote><h3 id="更新公共资源和CRD"><a href="#更新公共资源和CRD" class="headerlink" title="更新公共资源和CRD"></a>更新公共资源和CRD</h3><pre class="line-numbers language-none"><code class="language-none">kubectl apply -f common.yaml -f crds.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>无报错即可</p></blockquote><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111702042.png" alt="image-20211222180427314"></p><h3 id="更新-Ceph-CSI-版本"><a href="#更新-Ceph-CSI-版本" class="headerlink" title="更新 Ceph CSI 版本"></a>更新 Ceph CSI 版本</h3><blockquote><p>由于ceph升级了，所以我们需要升级<code>csi</code></p></blockquote><h4 id="修改csi镜像配置"><a href="#修改csi镜像配置" class="headerlink" title="修改csi镜像配置"></a>修改csi镜像配置</h4><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_OPERATOR_NAMESPACE edit configmap rook-ceph-operator-configdata:  CSI_FORCE_CEPHFS_KERNEL_CLIENT: "true"  ROOK_CSI_ALLOW_UNSUPPORTED_VERSION: "false"  ROOK_CSI_ENABLE_CEPHFS: "true"  ROOK_CSI_ENABLE_GRPC_METRICS: "true"  ROOK_CSI_ENABLE_RBD: "true"  ROOK_OBC_WATCH_OPERATOR_NAMESPACE: "true"  ROOK_CSI_CEPH_IMAGE: "cncp/csi/cephcsi:v3.2.2"  ROOK_CSI_REGISTRAR_IMAGE: "cncp/csi/csi-node-driver-registrar:v2.0.1"  ROOK_CSI_PROVISIONER_IMAGE: "cncp/csi/csi-provisioner:v2.0.4"  ROOK_CSI_SNAPSHOTTER_IMAGE: "cncp/csi/csi-snapshotter:v3.0.2"  ROOK_CSI_ATTACHER_IMAGE: "cncp/csi/csi-attacher:v3.0.2"  ROOK_CSI_RESIZER_IMAGE: "cncp/csi/csi-resizer:v1.0.1"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111702204.png" alt="image-20211222182632326"></p><h4 id="验证更新-Operator更新后验证"><a href="#验证更新-Operator更新后验证" class="headerlink" title="验证更新(Operator更新后验证)"></a>验证更新(Operator更新后验证)</h4><pre class="line-numbers language-none"><code class="language-none">kubectl --namespace rook-ceph get pod -o jsonpath='{range .items[*]}{range .spec.containers[*]}{.image}{"\n"}' -l 'app in (csi-rbdplugin,csi-rbdplugin-provisioner,csi-cephfsplugin,csi-cephfsplugin-provisioner)' | sort | uniqcncp/csi/cephcsi:v3.2.2cncp/csi/csi-attacher:v3.0.2cncp/csi/csi-node-driver-registrar:v2.0.1cncp/csi/csi-provisioner:v2.0.4cncp/csi/csi-resizer:v1.0.1cncp/csi/csi-snapshotter:v3.0.2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111702849.png" alt="image-20211227152733044"></p><h3 id="更新Operator"><a href="#更新Operator" class="headerlink" title="更新Operator"></a>更新Operator</h3><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_OPERATOR_NAMESPACE set image deploy/rook-ceph-operator rook-ceph-operator=cncp/csi/operator-ceph:v1.5.11<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111702018.png" alt="image-20211222181418290"></p><h3 id="等待升级完成"><a href="#等待升级完成" class="headerlink" title="等待升级完成"></a>等待升级完成</h3><blockquote><p>现在Ceph mons、mgrs、OSD被终止并被依次更新的版本替换。</p><p>集群可能会在 mons 更新时非常短暂地脱机，这是正常现象</p><p>可以通过下面命令进行插件，当查看命令结果<code>rook-version</code>都替换为v1.5.11</p></blockquote><pre class="line-numbers language-none"><code class="language-none">watch --exec kubectl -n $ROOK_CLUSTER_NAMESPACE get deployments -l rook_cluster=$ROOK_CLUSTER_NAMESPACE -o jsonpath='{range .items[*]}{.metadata.name}{"  \treq/upd/avl: "}{.spec.replicas}{"/"}{.status.updatedReplicas}{"/"}{.status.readyReplicas}{"  \trook-version="}{.metadata.labels.rook-version}{"\n"}{end}'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE get deployment -l rook_cluster=$ROOK_CLUSTER_NAMESPACE -o jsonpath='{range .items[*]}{"rook-version="}{.metadata.labels.rook-version}{"\n"}{end}' | sort | uniq集群未完成升级:  rook-version=v1.4.9  rook-version=v1.5.11集群已经完成升级:  rook-version=v1.5.11<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>升级中</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111702880.png" alt="image-20211222181452066"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704868.png" alt="image-20211222181553745"></p><ul><li>升级完成</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704868.png" alt="image-20211222181831082"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704869.png" alt="image-20211222181852385"></p><h3 id="验证更新的集群"><a href="#验证更新的集群" class="headerlink" title="验证更新的集群"></a>验证更新的集群</h3><ol><li><code>osd-prepare</code>为<code>Completed</code>状态，其余所有<code>pods</code>都为<code>Running</code>状态，如下图</li></ol>  <pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE get pods<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703437.png" alt="image-20211222151959138"></p><ol start="2"><li>Ceph集群状态查询</li></ol><blockquote><ul><li>集群健康：整体集群状态是<code>HEALTH_OK</code>，没有显示警告或错误状态消息。</li><li>监视器（mon）：所有监视器都包含在<code>quorum</code>列表中。</li><li>管理器（mgr）：Ceph 管理器处于<code>active</code>状态。</li><li>OSD (osd)：所有 OSD 都是<code>up</code>和<code>in</code>。</li><li>归置组 (pgs)：所有 PG 都在<code>active+clean</code>状态中。</li></ul></blockquote>  <pre class="line-numbers language-none"><code class="language-none">TOOLS_POD=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703672.png" alt="image-20211222182230713">  <img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703271.png" alt="image-20211222152246414"></p><h3 id="ceph版本升级"><a href="#ceph版本升级" class="headerlink" title="ceph版本升级"></a>ceph版本升级</h3><h4 id="升级到-Ceph-Octopus"><a href="#升级到-Ceph-Octopus" class="headerlink" title="升级到 Ceph Octopus"></a>升级到 Ceph Octopus</h4><ol><li>更新ceph守护进程daemons</li></ol><pre class="line-numbers language-none"><code class="language-none">NEW_CEPH_IMAGE='cncp/csi/ceph:v15.2.11'CLUSTER_NAME="$ROOK_CLUSTER_NAMESPACE"  # change if your cluster name is not the Rook namespacekubectl -n $ROOK_CLUSTER_NAMESPACE patch CephCluster $CLUSTER_NAME --type=merge -p "{\"spec\": {\"cephVersion\": {\"image\": \"$NEW_CEPH_IMAGE\"}}}"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703944.png" alt="image-20211222183139043"></p><ol start="2"><li>等待守护进程pod更新完成</li></ol><pre class="line-numbers language-none"><code class="language-none">watch --exec kubectl -n $ROOK_CLUSTER_NAMESPACE get deployments -l rook_cluster=$ROOK_CLUSTER_NAMESPACE -o jsonpath='{range .items[*]}{.metadata.name}{"  \treq/upd/avl: "}{.spec.replicas}{"/"}{.status.updatedReplicas}{"/"}{.status.readyReplicas}{"  \tceph-version="}{.metadata.labels.ceph-version}{"\n"}{end}'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>升级中</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703307.png" alt="image-20211222183600961"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703730.png" alt="image-20211222183829546"></p><ul><li>升级完成</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703449.png" alt="image-20211222183847543"></p><h4 id="验证升级完成"><a href="#验证升级完成" class="headerlink" title="验证升级完成"></a>验证升级完成</h4><pre class="line-numbers language-none"><code class="language-none"># kubectl -n $ROOK_CLUSTER_NAMESPACE get deployment -l rook_cluster=$ROOK_CLUSTER_NAMESPACE -o jsonpath='{range .items[*]}{"ceph-version="}{.metadata.labels.ceph-version}{"\n"}{end}' | sort | uniq集群未升级完成:    ceph-version=14.2.7-0    ceph-version=15.2.4-0集群升级完成:    ceph-version=15.2.4-0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>升级中</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111703836.png" alt="image-20211222183656335"></p><ul><li>升级完成</li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704141.png" alt="image-20211222183906265"></p><h2 id="验证集群"><a href="#验证集群" class="headerlink" title="验证集群"></a>验证集群</h2><ul><li><p><code>osd-prepare</code>为<code>Completed</code>状态，其余所有<code>pods</code>都为<code>Running</code>状态，如下图</p><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE get pods<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704538.png" alt="image-20211222184555423"></p></li><li><p>Ceph集群状态查询</p><blockquote><ul><li>集群健康：整体集群状态是<code>HEALTH_OK</code>，没有显示警告或错误状态消息。</li><li>监视器（mon）：所有监视器都包含在<code>quorum</code>列表中。</li><li>管理器（mgr）：Ceph 管理器处于<code>active</code>状态。</li><li>OSD (osd)：所有 OSD 都是<code>up</code>和<code>in</code>。</li><li>归置组 (pgs)：所有 PG 都在<code>active+clean</code>状态中。</li></ul></blockquote><pre class="line-numbers language-none"><code class="language-none">TOOLS_POD=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>集群状态修复以及 集群状态查询</p></li></ul><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704049.png" alt="image-20211222184632889"></p><pre class="line-numbers language-none"><code class="language-none">TOOLS_POD=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph config set mon auth_allow_insecure_global_id_reclaim falseTOOLS_DEPLOY=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get deploy -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_OPERATOR_NAMESPACE set image deploy/$TOOLS_DEPLOY $TOOLS_DEPLOY=cncp/csi/operator-ceph:v1.5.11TOOLS_POD=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704869.png" alt="image-20211222185544033"></p><ul><li>rook版本</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE get deployment -l rook_cluster=$ROOK_CLUSTER_NAMESPACE -o jsonpath='{range .items[*]}{"rook-version="}{.metadata.labels.rook-version}{"\n"}{end}' | sort | uniq<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>ceph版本</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE get deployment -l rook_cluster=$ROOK_CLUSTER_NAMESPACE -o jsonpath='{range .items[*]}{"ceph-version="}{.metadata.labels.ceph-version}{"\n"}{end}' | sort | uniq<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704365.png" alt="image-20211222185616485"></p><h1 id="配置存储网络网络分析"><a href="#配置存储网络网络分析" class="headerlink" title="配置存储网络网络分析"></a>配置存储网络网络分析</h1><h2 id="升级条件"><a href="#升级条件" class="headerlink" title="升级条件"></a>升级条件</h2><ul><li>升级前环境健康检查成功</li></ul><h2 id="配置解析"><a href="#配置解析" class="headerlink" title="配置解析"></a>配置解析</h2><ul><li>osd-network.yaml</li></ul><pre class="line-numbers language-none"><code class="language-none">apiVersion: "k8s.cni.cncf.io/v1"kind: NetworkAttachmentDefinitionmetadata:  name: rook-cluster-nw  namespace: rook-cephspec:      config: '{        "cniVersion": "0.3.0",        "name": "cluster",        "type": "macvlan",        "master": "eth0",        "mode": "bridge",        "ipam": {          "type": "whereabouts",          "range": "172.17.29.100-172.17.29.200/24",     # 申请集群网络IP地址段或者范围          "routes": [          { "dst": "0.0.0.0/0" }          ],          "gateway": "172.17.29.247"                     # 申请集群网络IP网关          }        }'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>config-override.yaml </li></ul><pre class="line-numbers language-none"><code class="language-none">apiVersion: v1kind: ConfigMapmetadata:  name: rook-config-override  namespace: rook-cephdata:  config: |    [global]      cluster network = 172.17.29.0/24  # ceph 集群网络<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="配置网络插件"><a href="#配置网络插件" class="headerlink" title="配置网络插件"></a>配置网络插件</h2><pre class="line-numbers language-none"><code class="language-none">cd whereaboutskustomize build |kubectl apply -f -<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="修改rook-ceph"><a href="#修改rook-ceph" class="headerlink" title="修改rook-ceph"></a>修改rook-ceph</h2><pre class="line-numbers language-none"><code class="language-none">kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=0kubectl apply -f config-override.yaml -f osd-network.yamlkubectl patch cephclusters.ceph.rook.io -n rook-ceph   rook-ceph --type merge --patch "$(cat rook-ceph-network-patch.yaml)"kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="验证是否修改成功"><a href="#验证是否修改成功" class="headerlink" title="验证是否修改成功"></a>验证是否修改成功</h2><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph osd dump<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111705616.png" alt="image-20211224150055539"></p><h1 id="新增日志盘"><a href="#新增日志盘" class="headerlink" title="新增日志盘"></a>新增日志盘</h1><h2 id="配置日志盘条件"><a href="#配置日志盘条件" class="headerlink" title="配置日志盘条件"></a>配置日志盘条件</h2><ul><li>配置前环境健康检查通过</li><li>每块数据盘一块日志盘</li><li>日志盘的大小不小于数据盘的4%</li><li>配置数据盘时候需要下线对应数据盘进行初始化</li><li>下线数据盘需要考虑到当前集群容量是否可以满足当前机器移除后容量要求</li><li>下线数据盘需要考虑到当前集群容量是否可以满足当前机器移除后满足pool的容灾域要求（默认主机容灾）</li><li>日志盘需要时裸设备(<code>lsblk -f </code>)</li><li>逐步新增osd，切勿批量导致数据异常</li></ul><h2 id="集群检查"><a href="#集群检查" class="headerlink" title="集群检查"></a>集群检查</h2><ul><li>查看当前集群pool数量以及所有pool副本数</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph osd pool ls# 判断osd分布情况是否满足容灾域要求kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph osd pool get  bigstorage   sizekubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph osd tree<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="日志盘配置"><a href="#日志盘配置" class="headerlink" title="日志盘配置"></a>日志盘配置</h2><h3 id="模拟配置日志盘"><a href="#模拟配置日志盘" class="headerlink" title="模拟配置日志盘"></a>模拟配置日志盘</h3><blockquote><p>如，我需要将<code>test-rook-server2</code>上的<code>vdc</code>配置为<code>vdb</code>的日志盘</p></blockquote><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111705586.png" alt="image-20211224152949026"></p><h3 id="osd对应磁盘"><a href="#osd对应磁盘" class="headerlink" title="osd对应磁盘"></a>osd对应磁盘</h3><pre class="line-numbers language-none"><code class="language-none"># 得到所有OSD的PODSOSD_PODS=$(kubectl get pods --all-namespaces -l \  app=rook-ceph-osd,rook_cluster=rook-ceph -o jsonpath='{.items[*].metadata.name}')# OSD pods 找到对应设备for pod in $(echo ${OSD_PODS})do echo "Pod:  ${pod}" echo "Node: $(kubectl -n rook-ceph get pod ${pod} -o jsonpath='{.spec.nodeName}')" kubectl -n rook-ceph exec ${pod} -- sh -c '\  for i in /var/lib/ceph/osd/ceph-*; do    [ -f ${i}/ready ] || continue    echo -ne "-$(basename ${i}) "    echo $(lsblk -n -o NAME,SIZE ${i}/block 2&gt; /dev/null || \    findmnt -n -v -o SOURCE,SIZE -T ${i}) $(cat ${i}/type)  done | sort -V  echo'done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>根据输出我们可以判断得出<code>test-rook-server2</code>上的<code>vdb</code>为<code>osd2</code></p></blockquote><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111705797.png" alt="image-20211224154347323"></p><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111705626.png" alt="image-20211224154252629"></p><h3 id="判断移除下线配置osd的影响"><a href="#判断移除下线配置osd的影响" class="headerlink" title="判断移除下线配置osd的影响"></a>判断移除下线配置osd的影响</h3><ul><li>下线osd后集群容量是否可以承载当前集群的容量</li><li>下线osd后集群后满足pool的容灾域要求（默认主机容灾）</li></ul><h3 id="配置以及操作"><a href="#配置以及操作" class="headerlink" title="配置以及操作"></a>配置以及操作</h3><ul><li>设置operater</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111705909.png" alt="image-20211224161219205"></p><ul><li>新增日志盘</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl edit cephclusters.ceph.rook.io -n rook-ceph   rook-ceph# 修改前  storage:    config:      storeType: bluestore    nodes:    - devices:      - name: vdb      name: test-rook-server2    - devices:      - name: vdb      name: test-rook-server3    - devices:      - name: vdb      name: test-rook-server4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none"># 修改后  storage:    config:      storeType: bluestore    nodes:    - devices:      - config:          metadataDevice: vdc        name: vdb      name: test-rook-server2    - devices:      - name: vdb      name: test-rook-server3    - devices:      - name: vdb      name: test-rook-server4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>关闭osd</li></ul><pre class="line-numbers language-none"><code class="language-none">TOOLS_POD=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD --  bash ceph osd set noupceph osd down 2ceph osd out 2# 等待数据均衡完成<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704916.png" alt="image-20211224162646756"></p><ul><li>移除osd</li></ul><pre class="line-numbers language-none"><code class="language-none">ceph osd purge 2 --yes-i-really-mean-itceph osd unset noup<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704153.png" alt="image-20211224163133247"></p><ul><li>停止对应的<code>deploy</code></li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl delete deploy -n rook-ceph rook-ceph-osd-2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>⚠️格式化磁盘（别删除错了）</li></ul><pre class="line-numbers language-none"><code class="language-none">lsblk -f sgdisk --zap-all /dev/vdbdd if=/dev/zero of=/dev/vdb bs=1M count=100 oflag=direct,dsync# 删除对应的链接ll /dev/ce* |grep ceph--e95df59d--a57b--4 #（osd对应磁盘输出的名称）lrwxrwxrwx 1 167 167 111 Dec 24 10:40 osd-block-52c2c0f8-dec5-44ad-98a7-b9737fb853cf -&gt; /dev/mapper/ceph--e95df59d--a57b--4d76--9f93--d7f4a28652fe-osd--block--52c2c0f8--dec5--44ad--98a7--b9737fb853cffind  /dev/ -name osd-block-52c2c0f8-dec5-44ad-98a7-b9737fb853cf/dev/ceph-e95df59d-a57b-4d76-9f93-d7f4a28652fe/osd-block-52c2c0f8-dec5-44ad-98a7-b9737fb853cfdmsetup lsdmsetup  remove ceph--e95df59d--a57b--4d76--9f93--d7f4a28652fe-osd--block--52c2c0f8--dec5--44ad--98a7--b9737fb853cfrm -rf /dev/ceph-e95df59d-a57b-4d76-9f93-d7f4a28652fe/osd-block-52c2c0f8-dec5-44ad-98a7-b9737fb853cflsblk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>启动operator</li></ul><pre class="line-numbers language-none"><code class="language-none">kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><ul><li>在<code>test-rook-server2</code>上验证</li></ul><pre class="line-numbers language-none"><code class="language-none">lsblk -f <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704493.png" alt="image-20211224163853917"></p><ul><li>在<code>osd2 pod</code>内验证</li></ul><pre class="line-numbers language-none"><code class="language-none">ceph-volume lvm list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704262.png" alt="image-20211224164117775"></p><ul><li>查看集群状态</li></ul><pre class="line-numbers language-none"><code class="language-none">TOOLS_POD=$(kubectl -n $ROOK_CLUSTER_NAMESPACE get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}')kubectl -n $ROOK_CLUSTER_NAMESPACE exec -it $TOOLS_POD -- ceph status<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://buleye.oss-cn-shenzhen.aliyuncs.com/images/202201111704095.png" alt="image-20211224171326964"></p>]]></content>
      
      
      <categories>
          
          <category> rook-ceph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> rook-ceph </tag>
            
            <tag> csi </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
